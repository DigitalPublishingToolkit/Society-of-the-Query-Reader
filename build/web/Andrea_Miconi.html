<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="SotQreader.web.css" type="text/css" />
</head>
<body>
<h2 id="premise">Premise</h2>
<p>Let’s be honest: we don’t know exactly how Google works. However, we all use Google to get information, probably because everybody else does. And although available data is quite ambiguous and inconsistent,<em>everybody</em> means almost literally everybody: at the beginning of this decade, 65 percent of daily online searches in the United States were made through Google,<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> while in Italy the percentage of people who declared using Google had grown to 92 percent.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> To be more precise, though, some local markets show significant differences: Google’s algorithm is mostly supposed to be suitable for the Latin alphabet, and in all likelihood this is why some geo-cultural systems such as Russia or China are resistant to its hegemony.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> In any case, generally speaking, Google’s growing influence is exactly the first problem we have to face: in the last 15 years, the ‘big G’ has become the most powerful company in the history of cultural industries, and here it will be considered as such. A very simple fact, which nonetheless raises a radical question: how could such a monopoly emerge from the decentralized project of the World Wide Web?</p>
<p>And to be honest, I <em>do</em> use Google, but I am worried about the way it is shaping our culture. The interesting problem to tackle is that Google’s power is not about <em>censorship</em>. Such cases as the well-discussed deal between Google and the Chinese government or Google’s likely adherence to the Digital Millennium Copyright Act are indeed borderline cases; they are very telling but at the same time quite easy to detect. On the contrary, the main problem is ultimately Google’s ordinary strategies: the ‘Big Firewall’ working daily behind the scenes, the biased representation of reality proposed by an agency that pretends to be neutral even though it obviously is not. For this same reason, a critical analysis of Google’s power is seriously limited by two opposing things: one, the object to be analyzed also belongs to our daily experience, as often happens in social sciences, and two, we then have to take into account a device whose technical rules <em>we hardly understand</em>, as is common in the narrower field of platform studies or software studies. The two problems become one effect: the current paradigm in the organization of culture, which is universally affecting everyday practices, ultimately relies on a technological secret (to some extent, we could even consider Google’s algorithm as the digital version of the Coca-Cola recipe: everybody likes it, while nobody knows why or how it is actually made). Furthermore, awareness of this problem is nearly non-existent because of the perception of Google as a neutral and user-friendly (or even friendly) interface, and even as a beautiful, free of charge tool, likely to enable people to look for almost everything they want. But what is the secret of Google’s success, information for information’s sake, or something more complicated?</p>
<h2 id="the-kingdom-of-apparent-neutrality">The Kingdom of (Apparent) Neutrality</h2>
<p>Apparent neutrality: this could be a good definition for this search engine’s industrial strategies. In other words, Google’s lack of neutrality does not raise any problems; mass media and cultural agencies are never neutral, nor even expected to be. The problem with Google is that it is <em>perceived</em> as a neutral tool, rather than as an active gatekeeping function, while search engines, as Karine Barzilai-Nahon points out, play exactly the same part as human gatekeepers in traditional media.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> Nonetheless, while the role of traditional gatekeepers has been gradually brought to light, many surveys show how search engines are contrarily considered to be very reliable information sources. As for Google, we might wonder, to what extent is its white interface passing off as a neutral tool even though of course it is not? We could say that the stylistic choice of a plain white interface puts accent on neutrality, despite the information reduction and hierarchization through its algorithms. Google’s maybe not hiding all its filtering operations, but in a sense provides the user with the ‘promise of objectivity’, as Gillespie recently put it.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> It is no accident that the search result page – designed to be visibly free from any imposed frame – is visually very different from Google News, which on the contrary shows a very crowded page, full of information, images, and so forth.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> According to a Pew survey, 68 percent of users consider search engines as an 'unbiased source of information', and 62 percent of them are not capable of distinguishing between 'paid and unpaid results': for some reasons, people simply tend to 'trust search engines'<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> while no longer trusting traditional news media, and this attitude is arguably destined to give Google particular strength.</p>
<p>Does the problem ultimately rely on the software, or the people using it? According to the surveys focused on search engines, the web user – far from being <em>engaged</em>, as she is too often supposed to be – assumes a very <em>lazy</em> attitude. Most users, for example, only type a <em>one-word</em> query,<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> and very rarely combine more than three words,<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> in this way reducing complexity and limiting themselves to the minimum cognitive effort. Confirming other studies, Jansen, Spink, and Pedersen showed that most people usually dedicate no more than five minutes to a web search and, in so doing, tend to select nothing but the most common tools.<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> In other words, if search engines are, as stated years ago by Paul di Maggio et al., ‘biased in their identification and, especially, ranking of sites, the effects of this bias are compounded by the tendency of engine users to employ simple search terms and to satisfice by terminating searches at the first acceptable site’.<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a></p>
<p>Further, surveys show a more relevant tendency dealing with the way people normally receive and filter information. Between 60 and 80 percent of users read only the first ten results proposed by the search engine, and data vary marginally between surveys, making their general meaning clear. Those surveys are focused on the general use of search engines rather than on Google as a specific service, however they tell us something very important: people choose between <em>the first five or ten links</em> selected by the algorithm, which are, according to the original project, the most linked rather than the most reliable. Consider Larry Page and Sergey Brin’s 1998 presentation of Google:</p>
<blockquote>
<p>Academic citation literature has been applied to the web, largely by counting citations or backlinks to a given page. This gives some approximation of a page’s importance or quality. PageRank extends the idea by not counting links from all pages equally, and by normalizing by the number of links on a page.</p>
</blockquote>
<p>And the following ‘justification’ is that,</p>
<blockquote>
<p>Intuitively, pages that are well cited from many places around the web are worth looking at. If a page was not high quality, […] it is quite likely that Yahoo’s homepage would not link to it. PageRank handles both these cases and everything in between by recursively propagating weights through the link structure of the web.<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a></p>
</blockquote>
<p><em>Some approximation</em>, <em>intuitively</em>, <em>quite likely:</em> PageRank can possibly work as an indicator of quality – <em>possibly</em>, but this is not its main goal. PageRank’s quantitative bias is not a well-kept secret; this is generally the way Google works, and there is nothing bad in quantitative methodology as such. The problem is not that Google arbitrarily selects information, in this way establishing a cultural (and hence political) hierarchy. The problem is that this ranking is not perceived as arbitrary as it is, and has recently become a kind of universal and well-established hierarchy. The most striking aspect of the problem is that users only read the first results page,<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a> therefore basically <em>validating</em> without question the hierarchy arbitrarily established by the algorithm. Consequently, PageRank is ‘recursively propagating’ its bias and leading people to conform to what all the others are reading and (arguably) to take this as a given. As for the exact percentage of people who only read the first results page, data are not entirely consistent but are enough to allow some confidence in the findings: 70 percent in a 1999 study,<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a> 58 percent in a 2000 survey focused on Excite,<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a> 73 percent in a 2002 survey dedicated to nine different search engines,<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a> more than 72 percent in a 2005 research on AltaVista.<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a> Though clearly data vary, they account for the large majority of web users. If we look at more recent surveys, we can find some partial confirmations of previous tendencies. According to Jansen and Spink, web users are 'unwilling to invest additional effort to locate' relevant contents, and still show a 'low tolerance of viewing any results past the first page'.<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a> Statistical data released by Bing in 2013 show that 50 percent of users simply click the top result, while only '4-6 percent click the third result'.<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a> On the other hand, Keane, O’Brien and Smyth provided an empirical test by simulating a Google interface able to reverse the order of results, thus showing how people’s search is 'partially biased', even though users are sometimes able to detect the most relevant page even at the bottom of the list. <a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a> In other words, the degree to which the use of search engines is biased is still to be proved. The bias, however, exists, since users are barely aware of the way algorithms filter data and direct operations.</p>
<p>Unfortunately, the most part of available data reported in this article are too old to provide a clear understanding of the current use of search engines; however, they can help us raise some questions. What do they suggest? Simply and sadly, that often people do not see any reason to challenge search engines, or question their reliability and transparency. If we consider that people now limit their consumption to <em>one</em> search engine, the problem suddenly becomes evident.</p>
<h2 id="google-as-social-pattern">Google as Social Pattern</h2>
<p>I said earlier that people use only Google and so do I, but is this happening by accident or design? The reason why everybody uses Google could actually be simple: Google provides the most reliable results. We may however wonder to what extent such a universal usage ultimately depends on a clear understanding of technical performances – which should be based on a systematic comparison between <em>different</em> search engines – or rather on the pressure of current cultural frames. In this respect, we may wonder whether Google has been achieving dominance over its competitors through a two-step process. At a first level, quality arguably played a part: Google is considered to provide more complete and spam-free results than its competitors, and people prefer it over other search engines because of its accuracy and overall quality.<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a> What is more, the fact that Google is set as a default home page in some popular browsers has probably contributed to its universal adoption, or at it least to the consolidation of its leadership. For these reasons, it is actually difficult to distinguish between technical and social factors when it comes to analyzing their consequences on daily life practices. A social pattern, wrote Pierre Bourdieu, is basically a form of ‘habitus’:</p>
<blockquote>
<p>a system of durable, transposable dispositions, structured structures predisposed to function as structuring structures, that is, as principles of the generation and structuring of practices […] which can be adapted to their goals without presupposing a conscious aiming at ends or an express mastery of the operations necessary to attain them […].<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a></p>
</blockquote>
<p>Could things have gone differently? Obviously yes, but this is how social habitus works: as a piece of ‘history turned into nature’, explains Bourdieu, by which the class structure governs real practices through the mediation of a cultural scheme, able to engender ‘all the thoughts, all the conditions, all the actions consistent with those conditions, and no others’. As a consequence, people are forced to make a virtue out of necessity, ‘at the cost of double negation’, that is, ‘to refuse what is anyway refused and to love the inevitable’.<a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a> Was Google necessary? I do not know. Could people even <em>imagine</em> a Google-free life? Arguably no, or at least I don’t think so. <em>Double negation</em>, in Bourdieu’s explanation, means that you cannot desire something different from what the system wants you to desire, and now you cannot perceive as real something which is not included in Google. It seems that search engines eventually pass the test of an ontological proof.</p>
<p>In the end, the main difference between traditional and algorithm-driven media is this: all traditional media are each obviously biased, and this is arguably why audiences no longer trust them. As Manuel Castells pointed out, all recent international polls have been showing a very similar trend, according to which people barely believe in political parties, newspapers, and broadcasting media, all reported to be part of the same influential lobby. According to Castells, this dissatisfaction with traditional media is a first step toward discovering ‘mass self communication’: people <em>have</em> to get rid of TV, so as to explore the new possibilities opened up by the web.<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> But this time Castells is simply wrong, in my opinion. People do not believe in TV anymore, but they <em>do trust</em> Google, and his almost naïve distinction between ‘vertical’ and ‘horizontal’ media does not provide a serious understanding of power as it is now taking place within the new digital platforms.</p>
<h2 id="the-bubble-will-have-you">The Bubble Will Have You</h2>
<p>PageRank is simply the first stage in Google’s strategy. The second is characterized by the customization strategies through the use of cookies, most likely launched in 2007 after the acquisition of digital marketing company DoubleClick. The reasons behind this new strategy are difficult to discern: arguably, the limits of the traditional business model, which were only based on advertising revenues, played a part. In fact, for some time and especially before its stock went public, market conditions allowed Google to gather wealth by simply exploiting advertising links; however, a new problem arose when technological innovation finally promised web users the ability to skip the ad links.<a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a></p>
<p>In this sense, the massive use of cookies can be intended as a more narrow strategy to occupy the market: according to Eli Pariser, cookies allow Google to ‘extrapolate what you like’, and shape the search results according to your individual traffic history. More importantly, Google is now ‘filtering out’ all the information that is not supposed to be relevant for the target. Better yet, it is filtering out the information that is not relevant according to what the user has done <em>in the past</em>, in this way giving shape to an inherently static and <em>conservative</em> culture. The result of this customization practice is a ‘bubble’, a kind of <em>cage</em>, in which individuals experience a particular version of reality, different from that perceived by others.<a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a></p>
<p>To some extent, one could say, we have always been living in a ‘bubble’. Any mass medium – newspaper, television, etc. – provides a biased representation of reality, and thus in turn builds a kind of bubble, preventing its users from reading or watching all dissonant content. This is of course true, even though Google’s bubble is more dangerous, according to Eli Pariser, because it takes place at a very deep and hidden level, characterized by three main differences: it is narrow, invisible, and, what is more, almost impossible to avoid. ‘You are alone in the bubble’, he writes, it being built upon individual rather than collective preferences, and dedicated to a single consumption history rather than to a community, such as the audience of a TV channel. On the other hand, the new bubble is invisible: the framing operated by traditional media can be ambiguous, but at its first level you obviously <em>know</em> that you are accessing a given information environment, ruled by a given gatekeeper. Conversely, in the new bubble the user is no longer aware, for the cookies act at a very hidden level, such that you do not even know that cookies <em>exist</em>. For the very same reason, in the end the web user cannot decide to ‘enter the bubble’, as we do when choosing a magazine, radio station, or a movie. The bubble is choosing the user and surrounding his or her daily practices.<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a></p>
<p>Both PageRank and cookies reveal that Google <em>does</em> indeed filter information, in this way falsifying the ‘filter failure’ thesis suggested by David Weinberger<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a> (and, in different words, by Clay Shirky<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a>). According to Weinberger, the web is not properly affected by a serious overload, but rather a weakening of filters. It is this weakness of filters – which no longer filter out, according to his optimistic idea – that is simply showing the long forgotten state of our culture, that is, a disproportion between individual comprehension, on the one hand, and knowledge as a whole, on the other. Things are too big to know, Weinberger suggests, and the web simply reveals this well-kept secret; but in any case the idea that the new platforms simply filter forward and do not filter out is hardly suitable for the way algorithm works, and it is entirely wrong if we consider the deep effects of customization practices.</p>
<p>After PageRank and cookies, the next level is constituted, not by accident, by a kind of hybrid form likely to implement social network functions (Google+) in the search engine system. From the web at large to the personal network: this narrowing of cultural horizons can come as a surprise, but it is hardly unexpected if we consider that Google <em>does not trade information</em>, as it claims it does, but something very different. In a complex cultural system, as Tiziana Terranova recently noted, the true traded value is no longer information, but <em>attention</em>. While in fact the first is too widely available, the latter is under a scarcity regime, and is the ideal ‘condition that can give rise to a proper economy’.<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a> Therefore, ‘technology of attention’ is a good definition for what Google, along with other players, is now doing – gathering and trading people’s attention, and even reducing its information flow (to a great extent, attention for attention’s sake: the use of personal data is actually not as important as its control and storage). Or, as Rachael – <em>Blade Runner</em>’s most controversial replicant – famously said: I am not in the business; I <em>am</em> the business.</p>
<p>Page and Brin’s famous paper only describes the first stage in the evolution of Google, but we know that its functioning cannot be reduced to PageRank: its algorithms are actually based ‘on more than 200 unique signals’, including ‘the freshness of content’ and the user's region. <a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a> In the last years, Google has released many new features, such as ‘social search’, designed to ‘understand not only content but also people’, and allow users to find information directly related to them; <a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a> ‘knowledge search’, which introduces some elements of the so-called ‘semantic web’; <a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a> and Google Now, a service expected to provide you with the right information ‘before you even ask’, through the implementation of geo-locative technologies. <a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a> In short, Google combines many different services and tools, but I here consider only two of them – PageRank and the use of cookies – which seem to produce the most interesting effects. While the PageRank algorithm tends to favor the most linked pages, thus building a kind of homogenized agenda of knowledge and information, the use of cookies on the contrary leads to a very specific customization, likely to provide any user with a sort of individual ‘bubble’. So cookies oppose the tendency of PageRank, insofar as cookies model search results after the user’s individual tastes and preferences, which can be automatically detected. Google’s action is therefore splitting into two different and almost opposite tendencies: the maximum degrees of standardization and individualization, which becomes quite a challenge for social studies.</p>
<h2 id="dialectic-of-google">Dialectic of Google</h2>
<p>I’ve said the maximum degrees of standardization and individualization coexist in the same device. This seems to confirm Geert Lovink’s idea that in the stage of mass web diffusion there would no longer be a dominant tendency, whether we look for positive or negative effects of the internet.<a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a> But there is something more here. What emerges is in fact a new technical version of the most traditional sociological problem, the tension between individual and structure, and the rise of a new order, regulating the relationship between the two.</p>
<p>The role played by media and cultural industries in maintaining this balance has been widely investigated. In particular, Adorno and Horkheimer made a critical analysis in their <em>Dialectic of Enlightenment</em>:</p>
<blockquote>
<p>The sociological theory that the loss of the support of objectively established religion, the dissolution of the last remnants of precapitalism, together with technological and social differentiation or specialization, have led to cultural chaos is disproved every day; for culture now impresses the same stamp on everything.<a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a></p>
</blockquote>
<p>Even 70 years after Adorno and Horkheimer’s masterwork, this point remains: the idea according to which the evolution of our societies will eventually destroy all solid structures and lead to a kind of cultural chaos is simply ‘disproved’ by fact. According to Adorno, capitalist culture is stable (the ‘rhythm of the iron system’) rather than fluid, or, as we would say in present terms, post-modern or liquid. As Franco Moretti recently pointed out, Western bourgeoisie has actually been historically functioning as a conservative <em>force</em>, so as to normalize social turbulence, and build up a predictable pattern of everyday life – and ‘all that was solid’ eventually ‘became more so’.<a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a> At the same historical end, it seems that Google is stressing this tendency to its limits, ‘now impressing the same stamp on everything’ – <em>everything</em>: news and general contents, books and geographical maps, social circles and e-mail services, and so on. Two opposite and <em>dynamic</em> tendencies that nonetheless cooperate to produce a <em>static</em> result: the ‘inherently conservative’ nature of Google’s cultural processes by which, as discussed by Eli Pariser and Siva Vaidhyanathan, anyone will basically find what he or she is inclined to look for, and will eventually know what he or she already knows. The bubble, in this sense, is the ultimate technical version of a long-term process by which the individual has become a predictable part of a predictable statistical pattern:</p>
<blockquote>
<p>Everybody must behave (as if spontaneously) in accordance with his determined and indexed level, and choose the category of mass product turned out for his type. Consumers appear as statistics on research organization charts […]. The technique is that used for any type of propaganda.<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a></p>
</blockquote>
<p>Therefore, the individual bubble, the homogeneous global agenda, and the tension between the two factors can be regarded, to a considerable extent, as a tension of opposites. But do we really need such a complicated explanation as a <em>dialectic</em> of Google? More consideration needs to be given to three aspects of Google’s hegemony: the search algorithm, the contradiction between PageRank and the customization strategies, and finally the dynamic evolution of both tools.</p>
<p>PageRank obviously relies on <em>quantity</em>: the more links you have, the higher you will rank according to the algorithm’s hierarchies. We know what logically follows is the power law nature of the web: links, as almost any other resource, tend to cluster around a handful of sites, following the ‘80/20 rule’ of the Pareto principle.<a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a> In this sense, PageRank is neither establishing nor questioning a ranking, while the algorithm simply reproduces a previous hierarchy. This is why, following Vaidhyanathan, Google’s power has less to do with cultural than ‘infrastructural’ imperialism – the production of ideological content, or public opinion shaping, versus the control of the communication <em>process</em>as such.<a href="#fn40" class="footnoteRef" id="fnref40"><sup>40</sup></a> However, during this process, something is happening: quantity is definitely turning into <em>quality</em>, and for the very same reason – content does not matter, only links do. This tendency can be labeled simply as ‘the transformation of quantity into quality and vice versa’.</p>
<p>We’ve seen that this standardization tendency is counter-balanced by a different process, enabled by the use of cookies: a very narrow customization strategy, likely to build up a bubble around any individual profile. But the point I am most interested in is that Google’s inner process is not exhausted by either tendency, but is made of both, however contradictory they may be. Search results are organized according to the individual footprints detected by cookies, but ultimately rely on the same, common, <em>sterilized</em> cultural universe. Two opposite forces in the very same device – in other words, a kind of ‘interpenetration of opposites’.</p>
<p>However, this is not a static contradiction but a mobile tension, wherein any innovation is not just an advancement of a previous technology, but its overcoming through the exploration of a new evolutionary path. The PageRank algorithm, for example, is said to make the world too homogenous, with cookies now providing the opposite effect. Though Google can be blamed for destroying the copyright system and even the humanistic heritage as a whole, Google Books will eventually save it. We must still keep in mind all the polemics of the ‘virtual’ world and its likely effects on the representation of reality, as when Google Maps suddenly provides a hybrid representation of the planet, half ‘real’ and half ‘virtual’. Any process is a negation of the previous one, leading the system to a temporary equilibrium, destined in turn to give new transformation a place. Perhaps we could define this phenomenon with Hegel’s words: the ‘negation of negation’.</p>
<p>I will stop here, as I have attempted, in a half serious way, to apply Friedrich Engels' laws of dialectics to Google’s cultural system.<a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a> <em>Serious</em>, because I think that current technological innovation does require a strong theoretical investigation rather than a merely quantitative analysis usually operated through crawlers (which, in a sort of vicious circle, provide a further legitimation of commercial software as the only valuable cultural platform, and so on). <em>Half</em> not serious, because I am not actually sure that the traditional forms of thought – such as Engels' dialectics, or Bourdieu’s view of social practice – are the most suitable ones for the current needs of critical theory.</p>
<p>Absolutely, though, the two forces acting behind Google reproduce the basic tension between individualization and standardization that any social system is made of, while, at the same time, they move it to a next evolutionary level. What kind of sovereignty are we talking about with the homogenization of global knowledge and the ‘micro-physical’ customization of digital marketing? Put in different terms: cookies collect data in a cultural ecosystem where, for good or for bad, such things as violence, pornography, multiple names, anonymity (in a word, <em>dissonance</em>) have been banned. In this context, the individual is a consumer, tracked with any move he or she makes, and living in a digital market where there is no room for conflict. What a powerful device, and what an ideal habitus for the world order of late capitalism.</p>
<h2 id="references" class="references">References</h2>
<p>Adorno, Theodor and Max Horkheimer. <em>Dialectic of Enlightenment</em> (1944), London: Verso, 1997.</p>
<p>Barab á si, Albert-Laszlo. Linked: The New Science of Networks , New York: Perseus, 2002.</p>
<p>Barzilai-Nahon, Karine. 'Toward a Theory of Network Gatekeeping: A Framework for Exploring Information Control', <em>Journal of the American Society for Information, Science and Technology</em> 59.9 (2008): 1493-1512.</p>
<p>Bourdieu, Pierre. <em>Outline of a Theory of Practice</em>, Cambridge: Cambridge University Press, 1977 (1972).</p>
<p>Brin, Sergey, and Larry Page. 'The Anatomy of a Large-Scale Hypertextual Web Search Engine', Seventh International World Wide Conference, Brisbane, 1998, http://ilpubs.stanforde.edu:8090/361/.</p>
<p>Castells, Manuel. <em>Communication Power</em>, Oxford: Oxford University Press, 2009.</p>
<p>Di Maggio, Paul, Eszter Hargittai, W. Russell Neuman, and John P. Robinson. 'Social Implications of the Internet', <em>Annual Review of Sociology</em> 27 (2001): 307-336.</p>
<p>Engels, Friedrich. <em>Dialectics of Nature</em>, Minneapolis and St. Paul: Wellred, 2012 (1883).</p>
<p>Fallows, Deborah. ‘Search Engine Users. Internet Users are Confident, Satisfied and Trusting – but They Are also Unaware and Naïve’, Pew Internet &amp; American Life Project, 2005.</p>
<p>Gillespie, Tarleton. 'The Relevance of Algorithms', in Tarleton Gillespie, Pablo Boczkowski, and Kirsten Foot (eds), <em>Media Technologies</em>, Cambridge, MA: MIT Press, forthcoming.</p>
<p>Jansen, Bernard, and Amanda Spink. 'How We Are Searching the World Wide Web? A Comparison of Nine Search Engine Transaction Logs', <em>Information Processing and Management</em> 42 (2006): 252-256.</p>
<p>Jansen, Bernard, Amanda Spink, and Jan Pedersen. 'A Temporal Comparison of AltaVista Web Searching', <em>Journal of the American Society for Information, Science and Technology</em> 56.6 (2005): 559-570.</p>
<p>Jansen, Bernard, Amanda Spink, and Tefko Saracevic. ‘Real Life, Real Users, and Real Needs: A Study and Analysis of User Queries on the Web’, <em>Information Processing and Management</em> 36.3 (2000): 207-227.</p>
<p>Keane, Mark, Maeve O’Brien, Barry and Smyth. ‘Are People Biased in Their Use of Search Engines?’, <em>Communications of the ACM</em> 51.2 (2008): 49-52.</p>
<p>Lovink, Geert. <em>Zero Comments: Blogging and Critical Internet Theory</em>, New York: Routledge, 2007.</p>
<p>Moretti, Franco. <em>The Bourgeois between History and Literature</em>, London: Verso, 2013.</p>
<p>Pariser, Eli. <em>The Filter Bubble. What the Internet Is Hiding from You</em>, New York: Penguin, 2011.</p>
<p>Shirky, Clay. <em>Cognitive Surplus. Creativity and Generosity in a Connected Age</em>, New York: Penguin, 2010.</p>
<p>Silverstein, Craig, Monica Henzinger, Hannes Marais, and Michael Moricz. 'Analysis of a Very Large AltaVista Query Log', Newsletter ACM SIGIR Forum, 33.1 (1999): 6-12.</p>
<p>Spink, Amanda and Bernard Jansen. 'A Study of Web Search Trends', Webology 1 (2004), <a href="http://www.webology.ir/">www.webology.ir</a> .</p>
<p>Terranova,**Tiziana. 'Attention, Economy and the Brain', <em>Culture Machine</em> 13 (2012): 1-19.</p>
<p>Vaidhyanathan, Siva. <em>The Googlization of Everything (And Why We Should Worry)</em>, Berkeley and Los Angeles: University of California Press, 2011.</p>
<p>Vise, David, and Mark Malseed. <em>The Google Story</em>, New York: Random House, 2005.</p>
<p>Wang, Peiling, Michael Berry, and Yiheng Yang. 'Mining Longitudinal Web Queries: Trends and Patterns', <em>Journal of the American Society for Information Science and Technology</em> 54.8 (2003): 743-758.</p>
<p>Weinberger, David. <em>Too Big to Know</em>, New York: Basic Books, 2011.</p>
<h2 id="notes" class="notes">Notes</h2>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Data available at www.comscore.com.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Data available at www.fullplan.it.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Siva Vaidhyanathan, <em>The Googlization of Everything (And Why We Should Worry)</em>, Berkeley and Los Angeles: University of California Press, 2011, p. 144.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Karine Barzilai-Nahon, ‘Toward a Theory of Network Gatekeeping: A Framework for Exploring Information Control’, <em>Journal of the American Society for Information, Science and Technology</em> 59.9 (2008): 1493-1512.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Tarleton Gillespie, 'The Relevance of Algorithms', in Tarleton Gillespie, Pablo Boczkowski, and Kirsten Foot (eds) <em>Media Technologies</em>, Cambridge, MA: MIT Press, forthcoming.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>See David Vise and Mark Malseed, <em>The Google Story</em>, New York: Random House, 2005.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Deborah Fallows, ‘Search Engine Users. Internet Users are Confident, Satisfied and Trusting – but They Are Also Unaware and Naïve’, Pew Internet &amp; American Life Project, 2005, p 15.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Bernard Jansen and Amanda Spink, ‘How We Are Searching the World Wide Web? A Comparison of Nine Search Engine Transaction Logs’, <em>Information Processing and Management</em> 42 (2006): 252-256; see also Peiling Wang, Michael Berry, and Yiheng Yang, ‘Mining Longitudinal Web Queries: Trends and Patterns’, <em>Journal of the American Society for Information Science and Technology</em> 54.8 (2003): 743-758.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Bernard Jansen, Amanda Spink, and Tefko Saracevic, ‘Real Life, Real Users, and Real Needs: A Study and Analysis of User Queries on the Web’, <em>Information Processing and Management</em> 36.3 (2000): 216.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Bernard Jansen, Amanda Spink, and Jan Pedersen, ‘A Temporal Comparison of AltaVista Web Searching’, <em>Journal of the American Society for Information, Science and Technology</em> 56.6 (2005):**564.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>Paul Di Maggio, Eszter Hargittai, W. Russell Neuman, and John P. Robinson, ‘Social Implications of the Internet’, <em>Annual Review of Sociology</em> 27 (2001): 314.<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Sergey Brin and Larry Page, ‘The Anatomy of a Large-Scale Hypertextual Web Search Engine’, Seventh International World Wide Conference, Brisbane, 1998, http://ilpubs.stanforde.edu:8090/361/.<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>See Craig Silverstein, Monica Henzinger, Hannes Marais, and Michael Moricz, 'Analysis of a Very Large AltaVista Query Log', <em>Newsletter ACM SIGIR Forum</em> 33.1 (1999): 6-12.<a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>Amanda Spink and Bernard Jansen, ‘A Study of Web Search Trends’, <em>Webology</em> 1 (2004), www.webology.ir.<a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>Jansen, Spink, and Saracevic, 'Real Life, Real Users, and Real Needs', p. 215.<a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Jansen and Spink, 'How We Are Searching the World Wide Web?', pp. 257-258.<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>Jansen, Spink, and Pedersen, 'A Temporal Comparison of AltaVista Web Searching', p.**563.<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>Jansen and Spink, 'How Are We Searching the World Wide Web?' p. 260.<a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Data available at http://www.bing.com/blogs/site_blogs/b/searchquality/archive/2013/04/24/ten-blue-links-no-more-dynamic-page-sizing.aspx.<a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Mark Keane, Maeve O’ Brien, and Barry Smyth, ‘Are People Biased in Their Use of Search Engines?’ <em>Communications of the ACM</em> 51.2 (2008): 49-52.<a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Fellows, <em>Search Engine Users</em>, p. 14.<a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>Pierre Bourdieu, <em>Outline of a Theory of Practice</em>, Cambridge: Cambridge University Press, 1977 (1972), p. 78.<a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>Bourdieu, <em>Outline of a Theory of Practice</em>, p. 77.<a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Manuel Castells, <em>Communication Power</em>, Oxford: Oxford University Press, 2009.<a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>See Vise and Malseed, <em>The Google Story</em>.<a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>Eli Pariser, <em>The Filter Bubble. What the Internet is Hiding from You</em>, New York: Penguin, 2011.<a href="#fnref26">↩</a></p></li>
<li id="fn27"><p>Pariser, <em>The Filter Bubble</em>, pp. 9-10.<a href="#fnref27">↩</a></p></li>
<li id="fn28"><p>David Weinberger, <em>Too Big to Know</em>, New York: Basic Books, 2011.<a href="#fnref28">↩</a></p></li>
<li id="fn29"><p>Clay Shirky, <em>Cognitive Surplus. Creativity and Generosity in a Connected Age</em>, New York: Penguin, 2010.<a href="#fnref29">↩</a></p></li>
<li id="fn30"><p>Tiziana Terranova,<em>'</em>Attention, Economy and the Brain', <em>Culture Machine</em> 13 (2012): 2.<a href="#fnref30">↩</a></p></li>
<li id="fn31"><p>See, http://www.google.com/intl/en/insidesearch/howsearchworks/algorithms.html.<a href="#fnref31">↩</a></p></li>
<li id="fn32"><p>See, http://googleblog.blogspot.it/2012/01/search-plus-your-world.html.<a href="#fnref32">↩</a></p></li>
<li id="fn33"><p>See, http://www.google.com/insidesearch/features/search/knowledge.html.<a href="#fnref33">↩</a></p></li>
<li id="fn34"><p>See, http://www.google.com/landing/now/.<a href="#fnref34">↩</a></p></li>
<li id="fn35"><p>Geert Lovink, <em>Zero Comments: Blogging and Critical Internet Theory</em>, New York: Routledge, 2007.<a href="#fnref35">↩</a></p></li>
<li id="fn36"><p>Theodor Adorno and Max Horkheimer, <em>Dialectic of Enlightenment</em>, London: Verso, 1997 (1944), p. 120.<a href="#fnref36">↩</a></p></li>
<li id="fn37"><p>Franco Moretti, <em>The Bourgeois Between History and Literature</em>, London: Verso, 2013, p. 15.<a href="#fnref37">↩</a></p></li>
<li id="fn38"><p>Adorno and Horkheimer, <em>Dialectic of Enlightenment</em>, p. 123.<a href="#fnref38">↩</a></p></li>
<li id="fn39"><p>Albert-Laszlo Barab á si, Linked: The New Science of Networks , New York: Perseus, 2002.<a href="#fnref39">↩</a></p></li>
<li id="fn40"><p>Vaidhyanathan, <em>The Googlization of Everything</em>, pp. 110-114.<a href="#fnref40">↩</a></p></li>
<li id="fn41"><p>See Friedrich Engels, <em>Dialectics of Nature</em>, Minneapolis and St. Paul: Wellred, 2012 (1883).<a href="#fnref41">↩</a></p></li>
</ol>
</div>
</body>
</html>
