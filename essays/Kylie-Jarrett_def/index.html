<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
</head>
<body>
<p>A Database of Intention?</p>
<p>Kylie Jarrett</p>
<p>In his 2005 study of Google, industry analyst John Battelle describes the company’s technology as a ‘database of intentions’, ‘a massive clickstream database of desires, needs, wants, and preferences that can be discovered, subpoenaed, archived, tracked, and exploited for all sorts of ends’.<sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup> This database is a collation of each search term entered by a user and various other kinds of data, such as the geographic location of the computer’s IP address, the time spent on particular sites, and user preferences gleaned from profiles on various related sites such as YouTube, Google Books, Gmail, or Google+. These data are re-integrated into the Google infrastructure in various forms: as market demographic information, as personalization algorithms that refine search parameters, as mechanisms for algorithms to ‘learn’ natural language use, or as evidence of collective wisdom in ‘trending’ statistics, to name but a few instances of re-purposing. This vast archive is Google Inc.’s key monetizable resource, as its contents are sold to advertisers to generate the bulk of the company’s revenues. It is also a worrying feature of the cultural surveillance machinery of the contemporary geopolitical moment and its ongoing ‘war on terror’. As John Battelle says of Google’s database, this ‘living artifact of immense power […] is holding the world by its thoughts’.<sup><a href="#fn2" class="footnoteRef" id="fnref2">2</a></sup></p>
<p>But defining Google as a ‘database of intention’ raises a series of questions. What is ‘intention’ as a lived, embodied experience and can that really be captured by Google’s systems? What transformations occur in that capture, and are these the same across the broad range of systems and processes associated with Google’s database? What are the ideological, economic, and social implications of this capture? Ultimately, how may we understand Google’s relationship to our intentions? What follows is a series of reflections attempting to unravel some of the complexity suggested by describing Google as a database of intention. The interrelated vignettes seek to explore some of the tensions of Google’s data-mapping in order to complicate our picture of the political economy of search.</p>
<p>Vignette One: Intention and Alienation</p>
<p>When U.S. National Security Agency employee Edward Snowden bravely released information about the U.S. government clandestine surveillance operation codenamed PRISM, attention quickly turned to major internet sites such as Facebook and Google. It was claimed that not only was Google providing consumer records upon legally certified request, but also that the company had provided a ‘back door’ to its databases, allowing carte blanche access to unmediated user data. Senior executives made robust denials. Google CEO Larry Page and Chief Legal Officer David Drummond posted on the company’s official blog, ‘First, we have not joined any program that would give the U.S. government—or any other government—direct access to our servers. Indeed, the U.S. government does not have direct access or a “back door” to the information stored in our data centers. We had not heard of a program called PRISM until yesterday.’<sup><a href="#fn3" class="footnoteRef" id="fnref3">3</a></sup> With a variety of other high technology companies including Facebook, Apple, and Microsoft, and in alliance with non-profit and trade organizations such as Human Rights Watch and the American Civil Liberties Union, Google subsequently drafted a letter to legislators demanding more transparency in the surveillance operations of the U.S. government.<sup><a href="#fn4" class="footnoteRef" id="fnref4">4</a></sup></p>
<p>The anxiety experienced by these companies and their users about the security of these data reflects the implicit concern in Battelle’s understanding of Google as a database of intention that can be ‘discovered, subpoenaed, archived, tracked, and exploited for <em>all sorts of ends</em>’ (my emphasis). It is the ambiguity of these ends that worries many about the intentional capture of every entered search term. On one hand, the use of these data to personalize search and generate results pertinent to each individual are typically of little concern to the average user, and may indeed be considered a valuable facility. Similarly, the use of this broad-ranging data collection to enable ‘academic inquiry’ into usage practices, the original stated intention in building data capture into the system’s infrastructure,<sup><a href="#fn5" class="footnoteRef" id="fnref5">5</a></sup> is considered a fairly trouble-free, if not admirable, aspect of Google’s systems. These useful or mostly benign ends are one facet of Google’s gathering of intention.</p>
<p>On the other hand, ‘ends’ such as the wide-spread clandestine monitoring of user activity by more or less hostile state or corporate agencies exemplified by PRISM are conceived as a problem and a threat to privacy and the liberties that privacy assures.<sup><a href="#fn6" class="footnoteRef" id="fnref6">6</a></sup> These are serious and important concerns. If Google really is a database of our intentions for action or engagement in life, then access to that information breaches long held assumptions about the private possession of our own thoughts and desires. But it is not only privacy that is at stake in the possession of intention by commercial search sites such as Google.</p>
<p>The gathering of user information is the backbone of digital media economics. Typically based in advertising revenue models, the costs of using a ‘free’ site are the data each user actively or passively inputs, which become consumer traffic and demographic information that is sold to advertisers and marketers, often in real time. This economic model reconstitutes user activity into demographic and taste-identifying statistics, thereby transforming it into a commodity with economic exchange-value in the advertising marketplace. In doing so, it privatizes the energies of individuals and groups, effectively expropriating those resources from the subjective lived experience of each user, typically without fiscal compensation equal to the value of the economic surplus generated through this transformation. Such logic forms the basis of the capitalist economics of most of commercial search and the consumer web and has been explored extensively elsewhere.<sup><a href="#fn7" class="footnoteRef" id="fnref7">7</a></sup> What I wish to emphasize about this process though is not the exploitation that occurs because user inputs are not adequately compensated, but how the banking of intention by Google exemplifies and articulates the process of alienation inherent to the capitalist system.</p>
<p>Value is generated in capitalism when a worker’s possession of physical and intellectual energies is transferred to the capitalist, denying that laborer control over both the products of his or her labor as well as organization of the labor process. Activity and goods are no longer defined by their utility to the worker – use-value – who might use them to enrich their own lives, but in terms of the monetized value they can generate for the capitalist. This alienation of the worker from the products of their time and energy, and so from their own agency, is at the core of capitalism and at the core of search economics, where user data become commodities in an advertising market. Yet my intentions are meaningful only to me; they have an inalienable use-value for me in my lived existence. For this value to be transformed into a commodified object with exchange-value, over which I have no control and no right to claim sovereignty, is a powerful act of symbolic violence. In the process of reification and alienation of user activity inherent to the database of intention, my thoughts and activities are transformed into an alienated object that is no longer part of me, is not in my possession, and has agency that is not linked to my concerns. Once alienated, my intentions have the power to act upon me, autonomously of my desires, meanings, or interests.</p>
<p>In search contexts, our user data become the economic surplus that allows Google to continue to grow, build more server farms, and engage in research and development to identify new tools or systems to further capture our user data. It becomes that which allows Google Inc. to continue to be a capitalist enterprise and a ‘buyer of people’ as employees and as users.<sup><a href="#fn8" class="footnoteRef" id="fnref8">8</a></sup> In commercial contexts, where users have little to no capacity to influence the form of these technologies or industries, the user becomes affected from the outside by the forces released by their living labor (intention) transformed into the dead labor of capital (advertising data). The alienated commodity of each user’s data thus feeds back into the very same capitalist process that subjugates that user.</p>
<p>But it is more than merely Google’s particular domination of the user that is perpetuated in the way commodified user behavior acts upon us. As Astrid Mager describes, the ‘capitalist spirit gets embedded in search algorithms’ by way of the impetus users give to the continuation of search and its advertising-based metrics.<sup><a href="#fn9" class="footnoteRef" id="fnref9">9</a></sup> More than this, though, the penetration of commercial search through the fabric of our daily life perpetuates the social relationship of alienation inherent to capitalism itself in everyday activity, reiterating and normalizing a context where our desires and knowledge ‘naturally’ become the property of others and, as such, taken from our control. This phenomenon is certainly not isolated to search or commercial digital media, for it is the logic of the entire consumer complex. But whenever I instinctively reach for my phone to ‘ask Mr. Google’ that nagging question to which I do not know the answer, I participate in yet another perpetuation of that capitalist rationality. While our everyday uses of search may be in themselves benign, what the economics of Google’s database do is bind those intentions to the self-perpetuating circuits of capitalist production. At a global, systemic level, this is anything but a benign consequence of the database of intention.</p>
<p>If Google, both as a corporation and as a data structure, is primarily a web of user intentions, then this Marxist reading has serious implications for lives increasingly mediated by search. First, it asserts Google’s role in increasing estrangement from our lived experience, implying a further diminution of rich sociality. Second, it also implicates search in the perpetuation of capitalist relations, not simply because it is dominated by commercial entities, but because it helps to normalize and perpetuate the system’s underlying logic of expropriation and alienation. Revelations about PRISM and the potential for our intentions to act against us in state surveillance should be of concern. But these are merely extraordinary uses of Google’s database of intention. Its quotidian functioning as a mechanism for generating and perpetuating alienation is no less ideological and is as implicated in inequitable power dynamics, and it should concern us just as much.</p>
<p>Vignette Two: The Intentional Fallacy</p>
<p>As part of a discussion on issues of censorship and in an attempt to demonstrate the capacities of algorithms to dictate information retrieval, I recently conducted a search for the term ‘abortion’ using search engines from three countries with differing social and legal contexts for abortion: Australia, Ireland, and the U.S.. The study was not in any way systematic, and the results were fundamentally skewed by the search term being entered from a particular geographically located IP addresses. Nevertheless, the results usefully demonstrated for a diverse, generally non-technical audience how different versions of the same story appear for the same search term when different algorithmic parameters are applied.</p>
<p>While the data generated in this experiment was not valid, what did emerge of real interest was the subsequent display of advertising related to this search term in my Gmail account. For months, appearing in the sidebars of my email account were ads for Marie Stopes International, the U.K. women’s health service provider that many Irish women rely on when seeking a termination. This advertising appeared despite my never being logged into my Gmail account at the same time as I was conducting searches and gathering data for this project. This research was also conducted using different computers distributed between my work and home offices. My interest was piqued by this clear demonstration of how Google’s algorithmic surveillance links activity from each of my IP addresses, compiling activity across those addresses into an intentional logic that it then attributes to a singular umbrella profile spanning its many online properties.</p>
<p>Of greater interest though was how this also revealed the search engine’s inability to meaningfully understand the intentional logic of my searching. Evident in this persistent advertising of abortion services was the assumption that in entering the term ‘abortion’, I wanted to secure this procedure. In actuality I had no intention of seeking a termination, but every intention to research Google itself. Even with the aggregated activity of my IP address to inform its interpretation of these data, Google got it wrong. The purpose ascribed to me, and distributed across my digital identity, was not mine. While Google had a very clear idea of what I had searched for, my <em>intention</em> in conducting these searches was precisely what it didn’t, and perhaps couldn’t, adequately know. This leads to some important questions. Is it actually ‘intention’ that is captured by Google’s systems? Can intention be abstracted meaningfully into search terms? What is intention anyway?</p>
<p>Most dictionary, legal, and literary definitions associate intention with purposive action. However this frame doesn’t seem to capture what we pragmatically understand as intention. For instance, we may not intend to cause offense – our motivation may be humorous – but offense may still be found in our words. There is a disconnect between our actions, their effects, and our desires. What animates behavior is not necessarily co-extensive with its manifestation, shaped as the latter is by intervening social, cultural, and technological factors. The underlying drives, the rich tapestry of cognitions, experiences, embodied desires that shape any person’s goals, cannot be read directly off externalized activity. Google, therefore, can read and capture the extensive output of my search terms, but this is merely the mapping of my behavior rather than real insight into its motivational logic. My purpose may have been to search for ‘abortion’, but what animated that search was not contained in the term itself. Google was committing the intentional fallacy in assuming it could read my intentional logic from my output or in ascribing motivation to the range of behavioral traces I leave across my search activity, Gmail, Google+ profile, or YouTube viewing.</p>
<p>Further, what animates intention <em>prior to</em> its manifestation as purposive behavior is not necessarily transparent, even to the actor. This action may be shaped by non-purposive, non-rational, even non-cognitive drives. Embodied desire and affect move us in more or less conscious ways, fundamentally shaping our activities, including our search behaviors and the terms through which these manifest. Read this way, intention can be understood as involving both the purposive behavior manifest in search terms, but also an underlying affect. Drawing on the work of Brian Massumi, affect can be understood as those sensory practices of movement and feeling that function beyond the directly signifying properties of discourse, but which nevertheless constitute some of the lived existence – the cultural and social psychology – of all individuals. Affect is differentiated from emotion, for it is an intensity that is outside conscious articulation. Emotion, on the other hand, is ‘the sociolinguistic fixing of the quality of an experience’,<sup><a href="#fn10" class="footnoteRef" id="fnref10">10</a></sup> the resolution of affect into something we recognize and can articulate. This resolution qualifies the intensity of the experience, inserting it into knowable, narrativizable meaning. Emotion is ‘intensity owned and recognized [while] affect is unqualified. As such, it is not ownable or recognizable.’<sup><a href="#fn11" class="footnoteRef" id="fnref11">11</a></sup> Affect is the autonomous energy that motivates and non-rationally shapes our practices and intentions. It is a state of potential that cannot be captured or confined within a body, perception, or cognition without undergoing a fundamental transformation.</p>
<p>Intention, as extensively manifested as a search term, is similar to emotion in that it is a qualification of the non-rational motivating force of affect. The conceptualizing of a search goal transforms an autonomous moment of potential, the animating energy of a search, into an abstract and reductive ‘intention’, which does not directly correspond with the embodied, pre-conscious animating logics that give this intention its inherent meaning. The moment of chaos associated with affect when ‘a system enters a peculiar state of indecision, where what its next state will be turns entirely unpredictable’ is excessive and beyond the capture of any of our cultural, psychological, and technological mechanisms.<sup><a href="#fn12" class="footnoteRef" id="fnref12">12</a></sup> It certainly exceeds the value-making systems of Google’s database of intention because they cannot capture libidinal, affective energy. Shaped by the hyper-rationality of its engineering culture and the ultimate genericism of its algorithmic logic, Google’s technology is not well attuned to understand or engage with these elusive forces.</p>
<p>The intentions that constitute Google’s database must therefore be understood only as <em>ascriptions</em> of a limited conceptualization of intention and not as meaningful manifestations of the embodied affective logics of those intentions. The keywords and clickstream data it collects are reductive products of the full richness of our motivating energies. Certainly, they tell something about us, but they cannot ever reflect the panoply of desiring intentionality inherent to those searches. If Google can still be called a database of intentions, it is only of extensive manifestations – the textual, cognitive, discursive traces of digital activities. The affective, embodied use-values of these activities are simply not available to its algorithms and its data capture systems, no matter how sophisticated. Google cannot in actuality capture the meaningful, inalienable aspects of my intention. These cannot be alienated from me. They cannot be expropriated from me. And that is a source of comfort.</p>
<p>Vignette Three: Pre-empting Intention</p>
<p>The austerity of Google’s home search page is often commended. The simplicity of the page speaks to the infinite potential of the web and of search as a cultural activity. But when entering a search term, the complexity of the database that exists under that apparently transparent surface becomes manifest. Entering the term ‘intention’ into the empty search box invokes a range of Autocomplete suggestions, twisting through various permutations in time with the keystrokes of my typing. I journey from ‘i’, suggesting my often used sites ‘<em>Irish Times</em>’ or ‘Irish Rail’, to ‘in’, indicating ‘instagram’ or ‘indeed.ie’ (two sites I have barely and never used respectively), through various permutations until I enter ‘intention’ which suggests the term itself along with ‘intention to treat’, ‘intention tremor’, and ‘intention to create legal relations’. Whenever Google makes these helpful suggestions using Autocomplete or Knowledge Graph, or corrects spelling through Autocorrect, the lie is given to the concept of search as a transparent mediator of information on the web. The underlying data structures become too apparent to sustain that mythology.</p>
<p>But they also indicate a key aspect of Google’s data capture systems – they work through pre-emption. Knowing my intention is important for Google so it can anticipate my future search desires and propose helpful suggestions to make search ‘faster’, perpetuating its own dominance in a context where speed is valued. Pre-emption is the essence of the push mobile technology Google Now that, unbidden, offers users web services such as weather and traffic reports, news items, or information pertinent to appointments at times when their calendars and prior activity predict this information will be useful. The model of relevance Google uses in this technology and its search functions draws on data of each user’s past behavior along with aggregated generic data to propose a future model. This is then mobilized to propose personalized and yet generic search results and search suggestions shaped for that user. Thus, the intentions ascribed to each individual, constituted by an amalgam of that user’s search practices and the intentional logic ascribed to users as a mass, are deployed to guess the desires and orientations of each user and use and preemptively structure the search experience. When I enter ‘i’ it is assumed to mean ‘<em>Irish Times</em>’ and not the ‘<em>Irish Independent</em>’, ‘izakaya’, ‘iPhone’, or ‘igloo’, based on the intentions Google has associated with my profile and with similar users in my geographic and demographic areas. In these mechanisms, the intentions ascribed to me are fed back to me, working to inform my ongoing search articulations. A feedback loop emerges in which presumptions about activity, based on Google’s assumptions about users' intentions, go on to inform a user’s experience of, although not necessarily engagement with, the web.</p>
<p>The implications of this preemptive capture are broader than the display of easily ignored search options. Not only may search results be shaped by these expectations – search intentions themselves may become caught in the self-informing loops of what Tarleton Gillespie calls ‘public relevance algorithms’.<sup><a href="#fn13" class="footnoteRef" id="fnref13">13</a></sup> According to Massumi, during the transformation of affect into emotion, the unknowable potential of affect – its futurity – is folded back on itself, capturing that potential in the repetition and regularity of forms recognizable from previous states of resolution.<sup><a href="#fn14" class="footnoteRef" id="fnref14">14</a></sup> Similarly, the extensive manifestations of intention that are our search terms draw upon assumptions of valuable and effective keywords that we assume will find the search target. This occurs not only mechanically in the offerings of Autocomplete but in our own cognitive practices as searchers. Drawing upon our previous experiences, we search using terms we know or assume will get optimal results. For instance, I know that information about train timetables in Ireland is more likely to manifest using searches for ‘Irish Rail’, ‘Iarnród Éireann’, or ‘trains Ireland’ than the more whimsical term ‘choo-choos Emerald Isle’. Appropriate search terms, or search strategies, are effectively bookmarked in my head. The moment of articulating keywords – of articulating my intention – is thus already marked with infolded expectations of how Google’s mechanisms and algorithms will function. The potentiality of the embodied affective self is channeled in directions recognizable to and recognizable from the database of intention in order to achieve expected results.</p>
<p>The intention we articulate in search is thus previously shaped by the intentions we, and others, have already articulated into the database. In this recursive logic, the potential of futurity becomes limited by past resolutions. Embedding the output of search into the logics of search in this way can be understood as a form of control. It ‘forecloses the creative mutation’ of the affective potential of the search subject, instead channeling that potential into pre-ordained forms.<sup><a href="#fn15" class="footnoteRef" id="fnref15">15</a></sup> This preemptive shaping of our searching is momentous because we are adapting our knowledge logic to that of the commercially produced algorithm, generating a ‘calculated public’.<sup><a href="#fn16" class="footnoteRef" id="fnref16">16</a></sup> It enables the preemptive capture of our intentions, generating normative frameworks for ‘how we may think’, if I may upend Vannevar Bush’s seminal description of hypertextual environments.<sup><a href="#fn17" class="footnoteRef" id="fnref17">17</a></sup> When we articulate our desire into the forms of searchable intention, we are made over in the image of the algorithmic logic of search. Google’s database of intention may not capture the affective desires that animate our searches, but the logic of its algorithms can become so entwined with how we articulate those into intentions that the distinction becomes null and void.</p>
<p>Vignette Four: Intentional Subjects</p>
<p>In the vast architecture of Google’s collection of data is an ever-changing entity that is effectively ‘Me’. This is the version of Kylie Jarrett that Google has created and which it mobilizes in its personalization algorithms, in its various automated suggestions, in the advertising options it so helpfully displays for me, and in the lists of search results it provides as answers to my searches. This digital proxy, ascribed an intentionality that is not necessarily that of the biological ‘Me’, for all intents and purposes functions as ‘Me’ within the vast universe penetrated by Google. This ‘algorithmic identity’ grows and adapts with each instance of data, entered either actively or passively, that is attributed to the IP addresses and profiles that constitute the entity Google recognizes as Kylie Jarrett.<sup><a href="#fn18" class="footnoteRef" id="fnref18">18</a></sup></p>
<p>This is the database subject that in 1995 Mark Poster warned would come to dominate in the <em>Second Media Age</em>. Long before the ascendancy of search and the emergence of the social media network sites into which we pour various kinds of personal information, Poster raised concerns about the digital profiles being built from credit card use, marketing surveys, insurance information, electoral registers, and government institutional systems. He argued that the portraits of consumers built up in the relational databases of these institutions</p>
<p>become additional social identities as each individual is constituted for the computer, depending on the database in question, as a social agent. Without referring the database back to its owner and his or her interests or forward to the individual in question as a model of its adequacy or accuracy, we comprehend the database as a discursive production which inscribes positionalities of subjects according to its rules of formation.^^ <sup><a href="#fn19" class="footnoteRef" id="fnref19">19</a></sup></p>
<p>Like Poster’s database subjectivities, the person Google believes me to be lacks subtlety and is reductive and incomplete, and the intentions that Google attributes to me are shaped by the limitations of its data capture systems. However, that these intentions are not ‘really’ mine becomes irrelevant. Ascribed (fallacious) intentions that are then inscribed into my digital identity, my online existence becomes that which is constituted by the database’s expectations.<sup><a href="#fn20" class="footnoteRef" id="fnref20">20</a></sup> This ascribed and inscribed identity goes on to serve as the subject for whom personalization systems are built, for whom suggestions are made in Autocomplete, and it is the traces of this subject that advertisers and PRISM pick over to identify my role in the economy and the polity. With this agency, the database subject assumes a capacity to act upon me and to potentially act against me.</p>
<p>In recognizing this subject, we return to the alienation inherent in the economic logic of Google’s database of intention. But we are here not under the assumption that something intrinsic – our intentionality – has ‘really’ been captured and that this is the key cause for concern. In the ascriptive and inscriptive processes of the database, whether these are ‘my’ intentions or not does not alter their ability to represent ‘Me’. I am functionally and practically the subject cached in Google’s database for anyone who draws on these resources. If my Google traces show that I have searched for ‘abortion’, according to advertisers I have an interest in securing this procedure. In a state where abortion on demand is illegal, and where new legislation offers a jail term of up to 14 years for acquiring or assisting a termination, the potential for this subject to act against my interests is great. And if my experience of being online, including the preemptive structuring of my searches, is profoundly shaped by assumptions that I am this subject, how much does it matter that the affective logic of my searching escapes capture, remains inalienable and immanently resistant? In the brutal logic of an algorithmic world, how do I elude the shadow of my digital <em>doppelgänger</em>? What will it mean if I cannot?</p>
<p>In mobilizing a subject marked with ascribed and inscribed intent, Google is exerting what Parisi and Goodman describe as preemptive power.<sup><a href="#fn21" class="footnoteRef" id="fnref21">21</a></sup> Predicting behavior is a means of managing risk. It works by generating temporary normalizing categories through which future behavior is assessed and imbued with intelligibility. But it is a performative logic, bringing into existence the activity it proposes in the form of a response to that activity. This logic can be seen in the contemporary preemptive drone attacks across the Middle East and South Asia where calculations of the future serve as the basis for action in the present. An assumed threat of terrorism is acted upon in a preemptive drone strike as if it were already manifest, and in doing so the effects of the (non-existent) threat, which would be a retaliatory assault, are actualized. Preemption thus creates the future it proposes and also controls its effects prior to their manifestation. Such preemption is ultimately about, as Parisi and Goodman describe, intervening and engineering reality. As a governance system, preemptive power allows a State to be ready with policing and management processes that systematically modulate behavior based on calculations of likely behavior. This assures the continuation of a normative reality based on activities assessed by their presumed value.</p>
<p>Similarly, by ascribing intentions inferred from past behavior and then acting upon the anticipated, categorized, labeled, and valorized activity projected from these data, Google goes on to configure the future, shaping what becomes the (likely) search experience for each user. As Cheney-Lippold argues, the linking of ‘potential for alternative futures to our previous actions as users based on consumption and research for consumption’ generates a regulatory framework for activity.<sup><a href="#fn22" class="footnoteRef" id="fnref22">22</a></sup> When my search results are tailored only to the inferred intentions of the Kylie Jarrett in Google’s database, my access to information is effectively and opaquely marshaled. The path-dependency this creates ensures search activity increasingly understood through and regulated by the intentions ascribed to my database identity.<sup><a href="#fn23" class="footnoteRef" id="fnref23">23</a></sup> By assuming activity based on previously determined knowledge categorizations, the database of intention renders the searcher – as a mass, a more or less finely grained demographic, or as a particular user profile – a predictable and consequently manageable entity, while also securing the future by ensuring that appropriate predicted behavior is realized through mechanisms that structure the search experience. Google controls its subjects by preemptively ascribing and preparing for particular intentional subjects. To read intention from search terms, and to feed that intention back into the system in the form of technical (Autocomplete) or psychical mechanisms (the infolding of algorithmic logic into the articulation of intention) is thus an act of preemptive power.</p>
<p>At the level of the individual, this is never a totalizing, fully normalizing regulatory framework due to the ability of the database to absorb new data and reconstitute parameters accordingly. Nor are Google’s search predictions about imposing singular behavioral norms on individual users – these capacities have more to do ‘with capturing [users'] actions within a controllable framework’, providing control at a group or social level.<sup><a href="#fn24" class="footnoteRef" id="fnref24">24</a></sup> Google’s database identities thus have a role in biopolitics, in that they ‘give meaning to the categorizations that make up populations’ which are then used to ‘softly suggest’ particular avenues of activity to those categories of people.<sup><a href="#fn25" class="footnoteRef" id="fnref25">25</a></sup> The effects of this control are overtly demonstrated in the diverging search results generated for individual users whose profiles fall into differing class, racial, economic, gender, sexual, or geographic categories. The performativity of these constructed identities – that they bring about the behavior they are attributing to users – perpetuate these categorizations, feeding, and feeding into, assumptions about taste, ideology, and politics. These assumptions can then be mobilized at the level of the individual, sustaining social inequality through the ways information resources are delivered, or in macro-level governance systems, especially those of electioneering and market-driven state policy development that organize resources based on these assumptions. Offered as calculated insight, what emerges from the algorithms’ preemptive assessment of the intentions of constructed segments of the population can become the future.</p>
<p>That the identities at the base of this control are based on merely inferred and ascribed intentions makes their inscription into popular information systems such as Google a crucial political problem. This inscription by inference makes the question of the database of intention not only about economics or individual access to transparent and unbiased information sources, nor merely about the post-facto surveillance of any individual user’s database identity. It is the widespread mode of control ‘situated at a distance from traditional liberal politics, removed from civil discourse via the proprietary nature of many algorithms’ that these database subjects exemplify that should perhaps be giving us greatest pause.<sup><a href="#fn26" class="footnoteRef" id="fnref26">26</a></sup></p>
<p>A Database in Tension</p>
<p>To pull the various threads of these reflections together is not simple. Each vignette informs the other, but there is an inherent contradiction within them. The emphasis on the affective impetus behind search and its inherent unknowability and chaos outlined in the second vignette suggests possibilities to escape the control of the search algorithm. Contrarily, the constant return to questions of alienation, and the potential for the alienated subject generated by increasingly complex forms of preemptive capture to act upon us, suggests a mire from which there is no meaningful return. I am not convinced that Google is a database of intention, particularly not in the rich sense of intention as meaningfully resonant energy used here. I am equally sure, however, that it functions as if it were such, and that this reality assumes significance far beyond the delivery of irrelevant or inapt advertising. By way of summary then, I want to emphasize how in this dissonance lies possibility.</p>
<p>Google’s database – of search terms, of user behavior, of intention – is vast and pervasive. It has an ability to relate disparate traces of data and transform those data into, effectively, a subject with significance for us personally and politically – the searcher. But this data can never be absolute, for the searcher is excessive. The database subject is too reductive to capture the affective and libidinal subjectivity of the individual involved in the search. In her or his insistent potentiality, the searcher generates a futurity that must lie beyond the logic of this database, despite attempts to preempt that subjectivity. Consequently the subjectivity Google Search actually encounters always potentially slips beyond the knowable and explicable logic of the search algorithm and the advertising database. The searcher can thus never fully be captured by the economic system, even while remaining its product. To search then is to occupy this tenuous position both inside and potentially always outside its systemic logic.</p>
<p>Consequently, between the constantly mapping geography of the database of intentions and the terrain of everyday, embodied use is an inherent tension, but a tension from which the impetus for change can be built. In the disquieting and dissatisfying gaps between the desires that move us, that we intrinsically feel, and the tools through which we are able to manifest them as intentions is the potential to recognize the machinery of our digital mediators, to see through their apparently seamless integration into our lives. As Gillespie says in his call for greater public debate and engagement with algorithmic logics:</p>
<p>It is important that we conceive of this entanglement not as a one-directional influence, but as a recursive loop between the calculations of the algorithm and the “calculations” of people.<sup><a href="#fn27" class="footnoteRef" id="fnref27">27</a></sup></p>
<p>The tension at the heart of Google’s database opens a space not only for the passive resistance produced by affective excessiveness, but for mobilization and organization to ensure these databases and their algorithms are serving meaningful ends. While we may never want, or be capable of, producing a database that can actually capture intention and thus allow us better representation in technologically mediated systems, we may be able to work towards technological, social, and economic models that reduce the capacity of the reductive subjects of search to become alienated from our control and to work outside our interests. It is within the tension associated with intention that we can locate and promote struggle to better understand, to make transparent, and to reform the algorithmic logic of powerful mediators such as Google. This type of intervention should be an intentional goal of our interrogation of search.</p>
<p>References</p>
<p>Battelle, John. <em>The Search: How Google and Its Rivals Rewrote the Rules of Business and Transformed Our Culture</em>, New York: Penguin, 2005.</p>
<p>Brin, Sergey, and Larry Page. ‘The Anatomy of a Large-Scale Hypertextual Web Search Engine’, <em>Computer Networks and ISDN Systems</em> 30 (1998): 107-117. http://ilpubs.stanford.edu:8090/361/.</p>
<p>Bush, Vannevar. ‘As We May Think’, <em>Atlantic Monthly,</em> July 1945, http://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/.</p>
<p>Cheney-Lippold, John. ‘A New Algorithmic Identity: Soft Biopolitics and the Modulation of Control’, <em>Theory, Culture and Society</em> 28.6 (2011): 164-181.</p>
<p>Clough, Patricia Ticiento, Greg Goldberg, Rachel Schiff, Aaron Weeks and Craig Willse. ‘Notes towards a theory of affect itself’, <em>Ephemera</em> 7.1 (2007): 60-77.</p>
<p>Fuchs, Christian. <em>Internet and Society: Social Theory in the Information Age</em>, Oxfordshire: Routledge, 2008.</p>
<p>Gillespie, Tarleton. ‘The Relevance of Algorithms’, in Tarleton Gillespie, Pablo Boczkowski, and Kirsten Foot (eds) <em>Media Technologies</em>, Cambridge, MA: MIT Press, forthcoming,<br />http://www.academia.edu/2257984/The_Relevance_of_Algorithms_forthcoming_in_Tarleton_Gillespie_Pablo_Boczkowski_Kirsten_Foot_eds._Media_Technologies_MIT_Press_2013_.</p>
<ol style="list-style-type: decimal">
<li>Koetsier, John. ‘The full PRISM letter Google, Yahoo, Apple, Facebook, and Microsoft are sending congress’, <em>Venture Beat</em>, 18 July 2013, http://venturebeat.com/2013/07/18/the-full-prism-letter-google-yahoo-apple-facebook-and-microsoft-are-sending-congress/.</li>
</ol>
<p>2.</p>
<ol style="list-style-type: decimal">
<li>Mager, Astrid. ‘Algorithmic Ideology’, <em>Information, Communication &amp; Society</em> 15.5 (2012): 769-787.</li>
</ol>
<p>1.</p>
<p>Marx, Karl. <em>Capital: A New Abridgement</em>, ed. David McLellan, Oxford: Oxford University Press, 2008.</p>
<ol style="list-style-type: decimal">
<li><ol start="2" style="list-style-type: decimal">
<li>Massumi, Brian. <em>Parables for the Virtual: Movement, Affect, Sensation</em>, Durham and London: Duke University Press, 2002.</li>
</ol></li>
</ol>
<p>3.</p>
<p>Page, Larry and David Drummond. ‘What the…?’ Google Official blog, 7 June 2013, http://googleblog.blogspot.ie/2013/06/what.html.</p>
<p>Parisi, Luciana and Steve Goodman. ‘The Affect of Nanoterror’, <em>Culture Machine</em> 7 (2005), http://www.culturemachine.net/index.php/cm/article/viewArticle/29/36.</p>
<p>Pasquinelli, Matteo. ‘Google’s PageRank: Diagram of the Collective Capitalism and Rentier of the Common Intellect’, in Konrad Becker and Felix Stalder (eds) <em>Deep Search: The Politics of Search Beyond Google</em>, Innsbruck: Studienverlag, 2009, p. 152-162.</p>
<p>Poster, Mark. <em>The Second Media Age</em>, Cambridge: Polity Press, 1995.</p>
<p>Röhle, Theo. ‘Dissecting the Gatekeepers: Relational Perspectives on the Power of Search Engines’, in Konrad Becker and Felix Stalder (eds) <em>Deep Search: The Politics of Search Beyond Google</em>, Innsbruck: Studienverlag, 2009, p. 117-132.</p>
<p>Solove, Daniel J. <em>The Digital Person: Technology and Privacy in the Information Age</em>, New York: New York University Press, 2004.</p>
<p>Stalder, Felix and Christine Mayer. ‘The Second Index: Search engines, personalisation and surveillance’, in Konrad Becker and Felix Stalder (eds) <em>Deep Search: The Politics of Search Beyond Google</em>, Innsbruck: Studienverlag, 2009, p. 98-115.</p>
<p>Van Couvering, Elizabeth. ‘The History of the Internet Search Engine: Navigational Media and the Traffic Commodity’, in Amanda Spink and Michael Zimmer (ed) <em>Web Search: Multidisciplinary Perspectives</em>. Berlin: Springer-Verlag, 2008, p. 177-206.</p>
<h1 id="notes">Notes</h1>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>John Battelle, <em>The Search: How Google and Its Rivals Rewrote the Rules of Business and Transformed Our Culture</em>, New York: Penguin, p. 6.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Battelle, <em>The Search</em>, pp. 2-3.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Larry Page and David Drummond, ‘What the…?’, <em>Google Official Blog</em>, 7 June 2013, http://googleblog.blogspot.ie/2013/06/what.html.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>John Koetsier, ‘The Full PRISM Letter Google, Yahoo, Apple, Facebook, and Microsoft Are Sending Congress’, <em>Venture Beat</em>, 18 July 2013, http://venturebeat.com/2013/07/18/the-full-prism-letter-google-yahoo-apple-facebook-and-microsoft-are-sending-congress/.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Sergey Brin and Larry Page, ‘The Anatomy of a Large-Scale Hypertextual Web Search Engine’, <em>Computer Networks and ISDN Systems</em> 30 (1998): pp. 107-117, http://ilpubs.stanford.edu:8090/361/.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Daniel J. Solove, <em>The Digital Person: Technology and Privacy in the Information Age</em>, New York: New York University Press, 2004.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>For instance, Christian Fuchs, <em>Internet and Society: Social Theory in the Information Age</em>, Oxfordshire: Routledge, 2008; Matteo Pasquinelli, ‘Google’s PageRank: Diagram of the Collective Capitalism and Rentier of the Common Intellect’, in Konrad Becker and Felix Stalder (eds) <em>Deep Search: The Politics of Search Beyond Google</em>, Innsbruck: Studienverlag, 2009, pp. 152-162; Elizabeth Van Couvering, ‘The History of the Internet Search Engine: Navigational Media and the Traffic Commodity’, in Amanda Spink and Michael Zimmer (eds) <em>Web Search: Multidisciplinary Perspectives</em>, Berlin: Springer-Verlag, 2008, pp. 177-206.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Karl Marx, <em>Capital: A New Abridgement</em>, ed. David McLellan, Oxford: Oxford University Press, 2008, p. 384.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Astrid Mager, ‘Algorithmic Ideology’, <em>Information, Communication &amp; Society</em> 15:5 (2012), p. 779.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Brian Massumi, <em>Parables for the Virtual: Movement, Affect, Sensation</em>, Durham and London: Duke University Press, 2002, p. 28.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>Massumi, <em>Parables for the Virtual</em>, p. 28.<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Massumi, <em>Parables for the Virtual</em>, p. 109.<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>Tarleton Gillespie, ‘The Relevance of Algorithms’, in Tarleton Gillespie, Pablo Boczkowski and Kirsten Foot (eds) <em>Media Technologies</em>, Cambridge, MA: MIT Press, forthcoming.<br />http://www.academia.edu/2257984/The_Relevance_of_Algorithms_forthcoming_in_Tarleton_Gillespie_Pablo_Boczkowski_Kirsten_Foot_eds._Media_Technologies_MIT_Press_2013_.<a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>Massumi, <em>Parables</em>.<a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>Patricia Ticiento Clough, Greg Goldberg, Rachel Schiff, Aaron Weeks and Craig Willse, ‘Notes Towards a Theory of Affect Itself’, <em>Ephemera</em> 7.1 (2007): 70.<a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Gillespie, ‘Relevance of Algorithms’.<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>Vannevar Bush, ‘As We May Think’, <em>Atlantic Monthly,</em> July 1945, http://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/.<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>John Cheney-Lippold, ‘A New Algorithmic Identity: Soft Biopolitics and the Modulation of Control’, <em>Theory, Culture and Society</em> 28.6 (2011): 164-181.<a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Mark Poster, <em>The Second Media Age</em>, Cambridge: Polity Press, 1995, pp. 87-88.<a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Poster, <em>The Second Media Age</em>.<a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Luciana Parisi and Steve Goodman, ‘The Affect of Nanoterror’, <em>Culture Machine</em> 7 (2005), http://www.culturemachine.net/index.php/cm/article/viewArticle/29/36.<a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>Cheney-Lippold, ‘Algorithmic Identity’, p. 169.<a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>Felix Stalder and Christine Mayer, ‘The Second Index: Search Engines, Personalisation and Surveillance’, in Konrad Becker and Felix Stalder (eds) <em>Deep Search: The Politics of Search Beyond Google</em>, Innsbruck: Studienverlag, 2009, pp. 98-115.<a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Theo Röhle, ‘Dissecting the Gatekeepers: Relational Perspectives on the Power of Search Engines’, in Konrad Becker and Felix Stalder (eds) <em>Deep Search: The Politics of Search Beyond Google</em>, Innsbruck: Studienverlag, 2009, pp. 117-132.<a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>Cheney-Lippold, ‘Algorithmic Identity’, p. 173.<a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>Cheney-Lippold, ‘Algorithmic Identity’, p. 165.<a href="#fnref26">↩</a></p></li>
<li id="fn27"><p>Gillespie, ‘Relevance of Algorithms’.<a href="#fnref27">↩</a></p></li>
</ol>
</div>
</body>
</html>
