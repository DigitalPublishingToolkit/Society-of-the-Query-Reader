##Algorithming the Algorithm

##Martina Mahnke and Emma Uprichard

###&#35;hello

Imagine sailing across the ocean. The sun is shining, vastness all
around you. And suddenly [BOOM] you’ve hit an invisible wall. Welcome to
the Truman Show! Ever since Eli Pariser published his thoughts on a
potential filter bubble,[^1] this movie scenario seems
to have become reality, just with slight changes: it’s not the ocean,
it’s the internet we’re talking about, and it’s not a TV show producer,
but algorithms that constitute a sort of invisible
wall.[^2] Building on this assumption, most research is
trying to ‘tame the algorithmic tiger’.[^3] While this
is a valuable and often inspiring approach, we would like to emphasize
another side to the algorithmic everyday life. We argue that algorithms
can instigate and facilitate imagination, creativity, and frivolity,
while saying something that is simultaneously old and new, always almost
repeating what was before but never quite returning. We show this by
threading together stimulating quotes and screenshots from Google’s
autocomplete algorithms. In doing so, we invite the reader to
re-explore Google’s autocomplete algorithms in a creative, playful, and
reflexive way, thereby rendering more visible some of the excitement
and frivolity that comes from being and becoming part of the riddling
rhythm of the algorithmic everyday life.

###&#35;warning

We’ve adopted an alternative textual style, which may annoy and confuse
some readers, though hopefully also amuse and intrigue others. Therefore
we keep this discussion reasonably short and deliberately provocative.
However, we don’t want to confuse or provoke so that nothing is heard.
Our purpose is not to mess with the importance of academic prose for the
sake of it. Instead, what we do is experimental and reflects some of the
unexpected landings, spontaneity, and at times insanity of our
algorithmically-linked travels into (new and old) media spaces.

###&#35;searching

[IMG1]

("Fig. 1. I Google, therefore I am.")

Search engines in general, and Google in particular, have become entry
points to the internet. We use Google to verify information, to verify
credibility, to verify existence. Google seems to answer all of our
questions. ‘I google, therefore I am’? René Descartes tried to prove
existence by radically doubting his own; now visibility through Google
is used as proof. Google seems to be all-knowing and omnipresent. Is
Google the new God? The ‘Church of Google’ seeks proof through
scientific reasoning and concludes, ‘We at the Church of Google believe
the search engine Google is the closest humankind has ever come to
directly experiencing an actual God’.[^4] ‘To google’
has become today’s synonym for searching the web, even though official
language committees disfavor this trend. Sometimes it’s hard to imagine
what life would be without Google. What would we do? Use another search
engine? Not care about information on the internet?

Trying to answer these, albeit hypothetical, questions leads us to the
conclusion that Google is more than just a tool; it is a modern myth.
But let’s not forget, Google is still also ‘just’ a search engine. The
development of search engines can be divided into three periods from a
marketing perspective:[^5] (1) the period of
‘technological entrepreneurs’ from 1994 until 1997, (2) the period of
‘portals and vertical integration’ from 1997 until 2001, and (3) the
period of ‘syndication and consolidation’ starting in 2002, which still
persists. Google introduced its radically new search algorithm in the
second period in 1998.[^6] Google’s autocomplete
function was launched 1 April 2009, and it’s this autocomplete algorithm
that we want to focus on in our discussion.

Our aim is not a detailed critique of what has already been written on
the subject.[^7] Instead, we want to offer an
alternative way of thinking about search, to reflect some of
‘jagged-jixie’ involved when we casually surf, explore, and search the
web, when we find (not) new material, (not) new friends, and (not) new
colleagues – all the while speaking through and with the algorithm. We
aim to contribute to current discussions about the social implications
of algorithms. After all, algorithms are quintessentially social – they
are socially constructed and take on meanings that are variable across
time and space. Algorithms are full of ethical and political issues;
they (dis)connect the (inter)connected, and they are let loose by the
very few with the power and technical expertise to do so. So yes, we
know and agree that algorithms are powerful and governing, as so much of
the existing literature argues. However, algorithms can also instigate
imagination, creativity, and frivolity, if we allow them to. And all of
a sudden we might learn: their power is mutable, once we start playing
around.

###&#35;perspectives

From a mathematical perspective, algorithms have been around for
centuries. As Charbert summarizes in simple terms,[^8]
algorithms are recipes or step-by-step instructions. Algorithms were
used by the Babylonians for deciding points of law, as well as by Latin
teachers for teaching grammar. Today’s computer algorithms are more
complex processes, developed and translated into machine language by the
fields of machine learning and computer intelligence. In 1950 in his
‘game of imitation’, Alan Turing, one of the pioneers in this field,
raised this question for the first time: what if machines can
think?[^9] He theorized that if machines can imitate the
communication of a human, they could be considered just as intelligent.
While back then this speculation was a *gedankenexperiment*, it has now
almost, depending on the perspective, become true. An ordinary user is
not able to distinguish between machinery and human input anymore. Data
journalism – semi-automated production of text out of statistical data –
has taken over the simple text-producing routines of journalists. This
‘algorithmic turn’ can be seen in various areas in society. Even though
we are not entirely determined by technology, we are definitely living
in a world that is strongly driven by computational algorithmic
technology. This development can most clearly be seen in the area of
social media. While social media producers started with vague ideas and
deficient business models, they now are allocated a great part of the
internet, influencing our definition of what information is and how it
should be distributed.

Computational processes are carried out through algorithms. The
algorithms used in search engines are still a list of instructions, but
they are not as strict as ‘either-or’ rules; most of the time, they fall
into the category of intelligent algorithms, which means they learn and
change over time. Typically, authors tend to represent the issue of
algorithms as a question of control: who has control over what and whom?
This is a classic question of sovereignty, which introduces the notion
of hierarchy. Thought of this way, algorithms can be frightening; they
are surveilling, governing, and controlling. While exploring algorithms
and Google’s search algorithm from the perspective of power regimes is
valuable and inspiring, we’d like to highlight another side of our
algorithmic everyday life, namely what it means ‘to find’. To discover
something that may or may not have been searched. *Search and find need
one another*; they come together and make castles in the digital sand,
building layers upon layers of new configurations and algorithmic word
towers. What we have found is that algorithms can say something that is
simultaneously old and new, always almost repeating what was before, but
never quite returning. Fast forward. Rewind. Google’s autocomplete
search algorithm is another way of searching and finding, re-imagining,
creating, and playing with what is there already in the present and what
will be in the future. In other words, autocomplete instigates and
facilitates imagination, creativity, and frivolity.

###&#35;whatalgorithmsdo

Through their rule-based simplicity, algorithms enable a space, place,
and time to re-do the old and new simultaneously, nonlinearly, in an
awe-inspiring magical kaleidoscope. As Waldrop sums up beautifully:

As we begin to understand complex systems, we begin to understand that
we’re part of an ever-changing, interlocking, non-linear, kaleidoscopic
world. […] The elements always stay the same, yet they’re always
rearranging themselves. So it’s like a kaleidoscope: the world is a
matter of patterns that change [and have continuity], that partly
repeat, but never quite repeat, that are always new and
different.[^10]

Repeating and rearranging, threading and weaving, knitting the crochet
macabre macramé world of the web. Searching and re-searching. Re-finding
and de-re-finding. The new and the old. Growing and changing and not
changing together. The invariable, invariant variety of patterns in the
Googleland of the present. Past becomes the future of futures, time and
time and time again. Again. Repeat. The dynamics of the algorithmic
‘live’ search engine ensure the patterned repetition and ever-morphing
world.

Inputting, storing, processing, and outputting are the functions of our
algorithms; this is all they can (currently) do. We embrace the
algorithm and its rules-based logarithms; they are simple. If you are an
algorithm, there is no ambiguity. You need to know exactly which step,
which function, which action will be performed. Humans, on the other
hand, introduce ambiguity, fuzziness, and confusion. The unambiguous
algorithmic world combines with the lone surfer, who constantly flits
from one thought to the next, confusing paths, laying new stones for
those who follow, kicking up dust, masquerading as the present,
multiplying the future, and re-clicking a new and emergent present.
Masquerading at a ball, like a harlequin clown, juggling with hyperlinks
and net-edges, working and erasing time all the time.

It’s not just fun and play. Algorithms have social implications. Donald
Knuth,[^11] Thomas Corman et
al.,[^12] Steven Skiena,[^13] and
many authors have shown that the relationship between algorithms and the
social is complicated. But only sort of. There are so many ways to sort
and search the social. Clustering and classifying. Machines learning
patterns. Sorting this thing from that, in and out. This box, not that
one. With those and without these. Sorting what cannot be sorted easily.
Behind the ‘black box’ of search algorithms lies the need to sort out in
order to search. Indeed, a search algorithm mostly comes down to how we
measure and define difference and similarity, distance and proximity,
how something is measured to be ‘far’ or ‘near’. Scaling up and scaling
down. Ordering disorder. Always and everywhere. This or that. In short:
sorting is all about *matching* and *ranking*. Two items are matched
against each other and displayed in a ranked (dis)order.

###&#35;diggingintothealgorithm

In order to dig into Google’s autocomplete algorithm a little further,
we took screenshots and combined them with citations. We joined
co-authored emails and internet searches. To and from, as we both
searched for the search. Piecing together the incoherent. Reflecting the
process and the (con)text. Tracing and tracking, snatching and clipping.
In Denmark and the U.K. The data reflects the autoethnographic approach
taken. Participating and observing. Immersing. Taking notes. Memos.
Comments. Getting lost and coming back. In order to think, reflect, and
write. Understanding the internet as a *digging place* for
archaeological excavation. And using the internet to dig through the
autocompleted links.

###>start [enter]

[IMG 2]

("Fig. 2. Same but different.")

###&#35;thinkingmachines

What’s the difference between human and machine? Is there a difference?
Daniel Dennett [I’m feeling lucky ENTER] argues: ‘It is that special
inner light, that private way that is with you that nobody else can
share, something that is forever outside the bounds of computer
science.’[^14] Boden noted in 1985: ‘Artificial
intelligence (AI) was conceived in the mid-1940s […]. Since then, it has
had some notable successes, enabling computers to perform – albeit in a
very limited way – some of the tasks normally done by our
minds.’[^15] In the end isn’t AI just a copycat
copying what’s already there? Trying to reach the original, just never
quite getting there?

As can be seen in Figure 2, a quick search for ‘Can machines think?’,
typed in a sloppy everyday way, not caring about upper and lower cases
and question marks, in Denmark and the U.K., produces slightly
similar, but still different autocomplete terms. Yet, in Figure 3 we
notice it is not only that the autocompleted terms differ across
countries, but also across time. That is to say, the same search terms
used just 11 minutes apart make visible a different set of terms – some
the same and some new. In contrast, the same search terms two days apart
have no visible effect. While these outcomes raise concerns, they also
trigger a whole other possible set of reactions. Indeed, it is tempting
to immediately question the censoring and governing actions of the
algorithms, which delimit and determine the outcomes of our searches. We
want to suggest that it is precisely in the similarities and differences
of Google’s autocomplete that we are offered alternative ways of
‘playing’ with and against Google itself. Moreover, it is in making
visible these different and similar affordances that Google’s
autocomplete algorithm becomes both a site and a mechanism whereby
*imagination, creativity, and frivolity* produce accessibility.

[IMG 3]

("Fig. 3. Difference in time and space.")

[IMG 4]

("Fig. 4. Growing an ‘imagination tree’.")

###>end [stop]

###&#35;imagination

Imagination is a way of seeing, knowing, and learning; it asks us to
look beyond what we take for granted.[^16] Imagination
premises openness. Imagination builds on top of the known. Imagination
resides ‘where perception, memory, idea generation, emotion, metaphor,
and no doubt other labeled features of our lives, intersect and
interact’.[^17] The collected data shows that the
actual list of words varies across time and space. The differences and
similarities matter as much as they do not matter and simply echo
Google’s idea of relevance, trying to sense and predict the virtual
waves of the digital seas between man and machine. Imagining a world
without Google is now like remembering a world without computers. It is
not the world we live in. What is for sure: other things will take over,
replacing Google in a time to come. At the moment, however, our searches
begin and end with Google's stamp.

In Figure 4, for example, Google’s autocomplete algorithm has started a
new, imaginative story for us, where typing ‘algo’ with algorithm in
mind led us to ‘algonquin’, a hotel. Autocomplete allows us to see, use,
and re-invent. We might start nurturing an ‘imagination tree’. Any
number of stories might stem from Google’s autocomplete terms when used
and re-imagined creatively, and the stories might never have been
imagined without Google giving us some words to play with in the first
place.

But yes, Google also censors the unsearched. However, it’s inevitable
that we never know what we cannot know. Therefore, algorithms do have
the capacity to reinforce what we already know; this can also mean
reinforcing negative discourses. Baker and Potts, for example, suggest
that racist, homophobic, and sexist stereotypes are reinforced through
visible autocomplete words.[^18] Imagination, however,
may help to balance this out and let us find nuggets of word-worlds that
we may not have previously considered. How can a search engine know what
we do not know and may not want to know? In our data material, we find
that Google U.K. tends to make fewer words visible than Google Denmark.
Is it really Google, or, since the query is based on personal search,
does it rather have something to do with our own search behavior? Are
these really ‘missing’ words? Are they even hidden? Or just visible
somewhere else? Then how might we find them? Did no one ask for them?
Does no one care? The irony is that to answer these questions, we are
pulled into the mystery of Google, once again. Searching for answers
while Google has us trapped. Searching for the search to find the answer
to the search sucks us back into an almost never-ending quest to find
the answers to the questions we have never searched. However, this
search also allows us to maintain a sense of creativity.

###&#35;creativity

Creativity is process. Creativity constitutes. To view Google’s
autocomplete creatively can help us learn and think in new ways. The
initial conditions of our googled ideas vary across time and space,
depending on which words float to the top (Figure 3). As Alexander
suggests, ‘there is a deep and important underlying structural
correspondence between the pattern of a problem and the process of
designing a physical form which answers that
problem’.[^19] And so too is the case here: the
underlying structure of Google’s autocomplete algorithm presents its own
problem of form. That is to say, the physical form of the algorithm lies
in part in its effects. Conversely these effects shape the algorithm,
like a sculptor shape-shifting the clay he or she shapes, always
morphing dialectically together, yet always with a little more control
than the clay itself, which only becomes animated through the hands of
the sculptor. Google’s search enables us to find what we want to find,
but those discoveries are also shaped by a massively abnormal curve that
is constantly contorted by unpredictable word lists.

In turn, therefore, there is potential for maximizing our crowdsourcing
capacity to shape Google’s autocomplete in our favor. For example, what
would happen if we collectively ceased to use Google for just one day?
Alternatively, what if billions of users searched ‘capitalism needs to
change’ or ‘racism must be punished’ at the same time? Given the
recursivity built into Google’s autocomplete algorithm, which is clearly
sensitive to time and space, perhaps there is more we can do to change
normative attitudes than we may have yet realized. Perhaps the capacity
to act collectively towards a common good is by actively interacting
with Google’s autocomplete in ways that are similar to activist
movements. If Google can *shape* our views, perhaps we can use Google to
*change* our views?

###&#35;frivolity

>Frivolity is considered a harmless, unproductive activity outside the
more structured activity of play. Huizinga (1950) in Homo Ludens notes
that play is a 'free activity standing quite consciously outside of
“ordinary” life as not being serious, but at the same time absorbing the
player intensely and utterly.' Frivolity, on the other hand, is more
transitory and generally without rules or order.^^
[^20]

In *The Archaeology of the Frivolous* Jacques Derrida argues, among
other things, that frivolity is always seen as ‘bad’ and ‘dangerous’ and
that we can use it to disturb and deconstruct views that are taken for
granted.[^21] Indeed, one of the key points we want to
make is that search algorithms need to be carefully looked at and looked
after. We need to make sure that we know who is doing the looking and
looking after. However, we want to emphasize that even though search
algorithms tend to take on a life of their own once they are produced,
put into action, and acted upon, they are no different to any other
social construct. The power they are assigned, and the independence they
are seen to take on, are both socially constructed. Their power is made
to ‘hold’ in much the same way that statistical measures of significance
are ‘made’ to hold through the social practices and institutions that
reinstate them, as Desrosières argues in his excellent book, *The
Politics of Large Numbers*.[^22] Indeed, we go so far
as to say that search algorithms are constructions just as are objects
in science. As Collins and Pinch point out in their classic book, *The
Golem: What You Should Know About Science*, [^23] it
is not science that is ‘good’ or ‘bad’. Rather, what is done with and to
the world in the name of ‘science’ is what can be judged as good or bad.

Perhaps, as we have suggested throughout, it is not Google’s search
algorithm that is problematic, despite its power. Instead, it is perhaps
the things that we as individuals, and collectively as governments, may
(or may not) do (and don’t do) with Google which are problematic. In
itself, the autocomplete algorithm may be seen as a Golem, following
Collins and Pinch's logic. A mythological creature. A bit daft. Silly.
Playful. Not good or bad. Just searching. Waiting for instructions on
what to search for. In turn, therefore, we suggest that we can put
Google’s search algorithm to frivolous use to disrupt and disturb the
ordinary words that inscribe and shape our world. Using Google’s
autocomplete to resist and confuse. After all, for every ‘search’, there
needs to be a ‘find’ to discover something that may or may not have been
searched. Search and find need one another. [^24]
Browsing and laughing through hyperlinks, giggling away at the joy of
discovering and uncovering and recovering new spaces, new worlds, the
unexpected. Using Google frivolously to make up new algorithmic fables,
new tales, and new futures. Daily, mundanely. Juggling with hyperlinks
and autocorrect. Everyday. Every day. ‘Taming the algorithmic tiger’
with a smile, with frivolity, creativity, and imaginary rhythms.

###&#35;lessonstolearn

‘Ceci n’est pas une pipe’ – ‘this is not a pipe’. Magritte shows us that
things are not always what they appear to be. We live in a world in
which we rely heavily on information on the one hand, but, on the other,
cannot validate it anymore through our own experiences. Hence, we gather
information through various intermediaries such as Google’s autocomplete
algorithms. While in the era of print these intermediaries seemed
definite and somehow understandable, this is not the case anymore. Let’s
face it: the internet – once thought of as a free information space –
has become quite chaotic. Constant innovation within the area of digital
technology and machine intelligence offers algorithmic answers to
everyday information chaos. The concepts behind the algorithms are not
easy to grasp, especially when businesses rely on the secrecy of those
algorithms in order stay in business. This situation has created anxiety
about what kind of information users receive. Mostly it is feared that
when algorithms calculate their stream based on a set of rules that
nobody knows, information becomes one-sided. We don’t think this outcome
will necessarily be the case: search algorithms are not solely based on
the algorithm itself, but also on us as users and our search-and-find
behavior. *Let’s start accepting this state of things and stop
surrendering*.

Searching the search is finding difference and similarity, change and
stagnancy, always in time and space. Algorithms learn and change and
repeat and remain the same too. Search algorithms govern and are visibly
invisible; this much we already know. What we have done and need to do
now is – *play creatively*. What Google gives us is the chance to play
around. How boring would the world be if we always got the same results,
whatever we did? This actually gives us the opportunity to be active.
We’re not running into a wall that always stays the same no matter what.
Goodbye Google Truman Show! If we understand algorithms as mirrors, we
can actively take on responsibility to create our own mirror image. We
have never had that chance before. We have never been that kind of
‘enabled citizen’. Let’s stop measuring Google against some sort of
mythical normative standard and start to think about how we can use
Google creatively.

And importantly, we must not ignore the fun and delight and playfulness
of the search. After all, search is duality. Search allows us to make
sense of the world and ourselves in that world. Search is a verb.
‘Searching’ implies that the ‘searcher’ knows something about what they
are looking for. Indeed, we might say that:

Search

      =      Being curious.

      =      Looking for answers.

      =      Looking for the unknown.

      =      Finding.

      =      Finding the known.

      =      Finding the unknown.

      =      Finding questions.

      =      Being confused.

      =      Being surprised.

      =      Being not surprised.

      =      A social practice in different times but the same place.

      =      A social practice at the same time but in different places.

      =      A social practice that finds the same in different places
in different times.

      =      Searching for searches and finding searches.

      =      Jack-in-a-box, always and never a surprise, predictably
unpredictable.

###&#35;thestorybehind

The story started on Facebook in May 2013. Martina (author one) had set
up a new Facebook page and invited friends to ‘like’ the page. Emma
(author two) received such an invitation, not from Martina, as both
authors didn’t know each other, but instead from another of her Facebook
friends. The invitation was to ‘like’ a page called ‘Algorithmic Media
Spaces’, but the next day, Emma noticed that the name of the page had
changed to ‘Algorithmic Media’. Thinking that her friend had set up the
page, Emma sent a silly message asking about the change of title (Figure
5). ‘Algorithmic Media’, alias Martina, replied and explained.

[IMG 5]

("Fig. 5. Facebook conversation.")

This is how algorithms brought us together, just as they bring so much
of our world together, and they do so across time and space, everyday
(Figure 6).

[IMG 6]

("Fig. 6. How the authors are related in time and space.")

###&#35;thanks

We’d like to thank Philipp Lenssen ( http://outer-court.com ) for kindly
allowing us to use his image in the \#searching section. We have titled
it ‘I Google, therefore I am’. It’s not the original title. We further
like to thank Miriam Rasch and René König for their editorial effort.

###&#35;references

Alexander, Christopher. *Note on the Synthesis of Form*, Cambridge, MA:
Harvard University Press, 1964.

Baker, Paul and Amanda Potts. ‘“Why do white people have thin lips?"
Google and the Perpetuation of Stereotypes via Auto-Complete Search
Forms’,*Critical Discourse Studies* 10.2 (2013): 187-204.

Bates, Rodger A. and Emily Fortner. 'The Social Construction of
Frivolity', *The Journal of Professional and Public Sociology*, 5.1
(2013), http://digitalcommons.kennesaw.edu/jpps/vol5/iss1/5.

Beer, David. ‘Power Through the Algorithm? Participatory Web Cultures
and the Technological Unconscious’, *New Media & Society*11 (September
2009): 985-1002.

Boden, Margaret A. ‘The Social Impact of Thinking Machines’ in Tom
Forester (ed.) *The Information Technology Revolution*, Oxford: Basil
Blackwell, 1985, pp. 95-103.

Bucher, Taina. ‘Want to Be on the Top? Algorithmic Power and the Threat
of Invisibility on Facebook’, *New Media & Society* 14.7 (November
2012): 1164-1180.

Chabert, Jean-Luc. *A History of Algorithms*, Berlin, Heidelberg:
Springer, 1999.

Collins, Harry and Trevor Pinch. *The Golem: What You Should
Know about Science*, Cambridge, U.K.: Cambridge University Press,
1998.

Corman, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford
Stein. *Introduction to Algorithms*, Cambridge MA: MIT Press, 2009.

Dennett, Daniel. ‘Can Machines Think?’ in Christof Teuscher (ed.) *Alan
Turing: Life and Legacy of a Great Thinker*, Berlin: Springer, 2004.

Derrida, Jacques. *The Archeology of the Frivolous*, trans. J. Leavey
Jr., Pittsburg: Duquesne University Press, 1973.

Desrosières, Alain. *The Politics of Large Numbers: A History of
Statistical Reasoning*, trans. Camille Naish, Cambridge, MA: Harvard
University Press, 1998.

Egan, Kieran. *Imagination in Teaching and Learning: The Middle School
Years*, Chicago: The University of Chicago Press, 1992.

Gillespie, Tarleton. ‘Can an Algorithm Be Wrong? Twitter Trends, the
Specter of Censorship, and Our Faith in the Algorithms Around Us’,
Culture Digitally blog, 19 October 2011, http://culture
digitally.org/2011/10/can-an-algorithm-be-wrong/.

Knuth, Donald. *Fundamental Algorithms,*vol. 1 of *The Art of Computer
Programming*, Boston: Addison-Wesley, 1997 (1968).

\_\_\_\_\_, *Sorting and Searching,*vol. 3 of *The Art of Computer
Programming*, Boston: Addison-Wesley, 1993 (1973).

Lake, Robert. *A Curriculum of Imagination in an Era of Standardization:
An Imaginative Dialogue with Maxine Greene and Paulo Freire*, Charlotte,
NC: Information Age Pub, 2013.

Naughton, John. 'How Algorithms Secretly Shape the Way We Behave', *The
Guardian*, 15 December 2012,
http://www.guardian.co.uk/technology/2012/dec/16/networker-algorithms-john-naughton.

Pariser, Eli.*The Filter Bubble: What the Internet is Hiding from You*, London: Penguin Press, 2011.

Rieder, Bernhard. ‘Democratizing Search? From Critique to
Society-oriented Design’, in Konrad Becker and Felix Stalder (eds) *Deep
Search. The Politics of Search beyond Google*, Innsbruck: Studienverlag, 2009, pp. 133-151.

\_\_\_\_\_. ‘Networked Control: Search Engines and the Symmetry of
Confidence’, *International Review of Information Ethics* 3.1 (2005):
26-32.

Skiena, Steven. *The Algorithm Design Manual*, London: Springer, 2008.

Slavin, Kevin. 'How Algorithms Shape Our World', TED Talks, July 2011
http://www.ted.com/talks/kevin\_slavin\_how\_algorithms\_shape\_our\_world.html.

Steiner, Christopher. *Automate This: How Algorithms Came to Rule Our
World*, New York, NY: Portfolio/Penguin, 2012.

Turing, Alan. ‘Computing Machinery and Intelligence’, in Paul A. Meyer
(ed.) *Computer Media and Communication: A Reader*, Oxford: Oxford
University Press, 1999, p. 37-58.

Van Couvering, Elizabeth Jane. *Search Engine Bias*, PhD diss.,
Department Media and Communications, London School of Economics and
Political Science, London, U.K., 2009.

Waldrop, M. Mitchell. *Complexity: The Emerging Science at the Edge of
Order and Chaos*, New York: Simon and Schuster, 1992.

###&#35;notes

[^1]: 1 Eli Pariser, *The Filter Bubble: What the Internet is Hiding from You*, London: Penguin Press, 2011.

[^2]: 2 Kevin Salvin, 'How Algorithms Shape Our World', TED Talks, July
    2011,
    http://www.ted.com/talks/kevin\_slavin\_how\_algorithms\_shape\_our\_world.html;
    John Naughton, 'How Algorithms Secretly Shape the Way We Behave',
    *The Guardian,* 15 December 2012,
    http://www.guardian.co.uk/technology/2012/dec/16/networker-algorithms-john-naughton.

[^3]: David Beer, ‘Power Through the Algorithm? Participatory Web Cultures
    and the Technological Unconscious’, *New Media & Society*11
    (September 2009): 985; Taina Bucher, ‘Want to Be on the Top?
    Algorithmic Power and the Threat of Invisibility on Facebook’, *New
    Media & Society*14.7 (November 2012): 1164-1180; Tarleton Gillespie,
    ‘Can an Algorithm Be Wrong? Twitter Trends, the Specter of
    Censorship, and Our Faith in the Algorithms Around Us’, Culture
    Digitally blog, 19 October 2011, http://culture
    digitally.org/2011/10/can-an-algorithm-be-wrong/; Bernhard Rieder,
    ‘Democratizing Search? From Critique to Society-oriented Design’, in
    Konrad Becker and Felix Stalder (eds) *Deep Search. The Politics of
    Search beyond Google,* Innsbruck: Studienverlag, 2009,
    pp. 133-151; Bernhard Rieder. ‘Networked Control: Search Engines and
    the Symmetry of Confidence’, *International Review of Information
    Ethics* 3.1 (2005): 26-32; Christopher Steiner, *Automate This: How
    Algorithms Came to Rule Our World,* New York, NY: Portfolio/Penguin,
    2012.

[^4]: Church of Google, http://www.thechurchofgoogle.org/.

[^5]: Elizabeth Jane Van Couvering, *Search Engine Bias*, PhD diss.,
    Department Media and Communications, London School of Economics and
    Political Science, London, 2009.

[^6]: Van Couvering, *Search Engine Bias*, p. 113.

[^7]: A great reading list is available at
    http://governingalgorithms.org/resources/reading-list/.

[^8]: Jean-Luc Chabert, *A History of Algorithms,* Berlin, Heidelberg:
    Springer, 1999.

[^9]: Alan Turing, ‘Computing Machinery and Intelligence’, in: Paul A.
    Meyer (ed.) *Computer Media and Communication: A Reader,* Oxford:
    Oxford University Press, 1999, pp. 37-58.

[^10]: M. Mitchell Waldrop, *Complexity: The Emerging Science at the Edge
    of Order and Chaos,* New York: Simon and Schuster, 1992, p. 332.

[^11]: Donald Knuth, *Fundamental Algorithms*, vol. 1 of *The Art of
    Computer Programming*, Boston: Addison-Wesley, 1997 (1968); Donald
    Knuth, *Sorting and Searching,* vol. 3 of *The Art of Computer
    Programming,*Boston: Addison-Wesley, 1993 (1973).

[^12]: Thomas Corman et al., *Introduction to Algorithms,* Cambridge, MA:
    MIT Press, 2009.

[^13]: Steven Skiena, *The Algorithm Design Manual*, London: Springer,
    2008.

[^14]: Daniel Dennett, ‘Can Machines Think?’ In Christof Teuscher (ed.)
    *Alan Turing: Life and Legacy of a Great Thinker*, Berlin: Springer,
    2004, p. 313.

[^15]: Margaret A. Boden, ‘The Social Impact of Thinking Machines’ in
    Tom Forester (ed.)*The Information Technology Revolution*, Oxford:
    Basil Blackwell, 1985, pp. 95-103.

[^16]: Kieran Egan, *Imagination in Teaching and Learning: The Middle
    School Years,* Chicago: The University of Chicago Press, 1992.

[^17]: Robert Lake, *A Curriculum of Imagination in an Era of
    Standardization: An Imaginative Dialogue with Maxine Greene and
    Paulo Freire,* Charlotte, NC: Information Age Pub, 2013.

[^18]: Paul Baker and Amanda Potts, ‘“Why do white people have thin lips?"
    Google and the Perpetuation of Stereotypes via Auto-Complete Search
    Forms’, *Critical Discourse Studies* 10.2 (2013): 187-204.

[^19]: Christopher Alexander, *Note on the Synthesis of Form*, Cambridge,
    MA: Harvard University Press, 1964, p. 132.

[^20]: Rodger A. Bates and Emily Fortner, 'The Social Construction of
    Frivolity', *The Journal of Professional and Public Sociology*, 5.1
    (2013), http://digitalcommons.kennesaw.edu/jpps/vol5/iss1/5.

[^21]: Jacques Derrida, *The Archeology of the Frivolous*, trans. J. Leavey
    Jr., Pittsburg: Duquesne University Press, 1973.

[^22]: Alain Desrosières, *The Politics of Large Numbers: A History of
    Statistical Reasoning*, trans. Camille Naish, Cambridge, MA: Harvard
    University Press, 1998.

[^23]: Harry Collins and Trevor Pinch, *The Golem: What You Should
    Know about Science,* Cambridge, U.K.: Cambridge University Press,
    1998.

[^24]: See #intro.



