---
Title: Dialectic of Google
Author: Andrea Miconi
---

##Premise

Let’s be honest: we don’t know exactly how Google works. However, we all
use Google to get information, probably because everybody else does. And
although available data is quite ambiguous and inconsistent,*everybody*
means almost literally everybody: at the beginning of this decade, 65
percent of daily online searches in the United States were made through
Google,[^1] while in Italy the percentage of people who
declared using Google had grown to 92 percent.[^2] To be
more precise, though, some local markets show significant differences:
Google’s algorithm is mostly supposed to be suitable for the Latin
alphabet, and in all likelihood this is why some geo-cultural systems
such as Russia or China are resistant to its
hegemony.[^3] In any case, generally speaking, Google’s
growing influence is exactly the first problem we have to face: in the
last 15 years, the ‘big G’ has become the most powerful company in the
history of cultural industries, and here it will be considered as such.
A very simple fact, which nonetheless raises a radical question: how
could such a monopoly emerge from the decentralized project of the World
Wide Web?

And to be honest, I *do* use Google, but I am worried about the way it
is shaping our culture. The interesting problem to tackle is that
Google’s power is not about *censorship*. Such cases as the
well-discussed deal between Google and the Chinese government or
Google’s likely adherence to the Digital Millennium Copyright Act are
indeed borderline cases; they are very telling but at the same time
quite easy to detect. On the contrary, the main problem is ultimately
Google’s ordinary strategies: the ‘Big Firewall’ working daily behind
the scenes, the biased representation of reality proposed by an agency
that pretends to be neutral even though it obviously is not. For this
same reason, a critical analysis of Google’s power is seriously limited
by two opposing things: one, the object to be analyzed also belongs to
our daily experience, as often happens in social sciences, and two, we
then have to take into account a device whose technical rules *we hardly
understand*, as is common in the narrower field of platform studies or
software studies. The two problems become one effect: the current
paradigm in the organization of culture, which is universally affecting
everyday practices, ultimately relies on a technological secret (to some
extent, we could even consider Google’s algorithm as the digital version
of the Coca-Cola recipe: everybody likes it, while nobody knows why or
how it is actually made). Furthermore, awareness of this problem is
nearly non-existent because of the perception of Google as a neutral and
user-friendly (or even friendly) interface, and even as a beautiful,
free of charge tool, likely to enable people to look for almost
everything they want. But what is the secret of Google’s success,
information for information’s sake, or something more complicated?

##The Kingdom of (Apparent) Neutrality

Apparent neutrality: this could be a good definition for this search
engine’s industrial strategies. In other words, Google’s lack of
neutrality does not raise any problems; mass media and cultural agencies
are never neutral, nor even expected to be. The problem with Google is
that it is *perceived* as a neutral tool, rather than as an active
gatekeeping function, while search engines, as Karine Barzilai-Nahon
points out, play exactly the same part as human gatekeepers in
traditional media.[^4] Nonetheless, while the role of
traditional gatekeepers has been gradually brought to light, many
surveys show how search engines are contrarily considered to be very
reliable information sources. As for Google, we might wonder, to what
extent is its white interface passing off as a neutral tool even though
of course it is not? We could say that the stylistic choice of a plain
white interface puts accent on neutrality, despite the information
reduction and hierarchization through its algorithms. Google’s maybe not
hiding all its filtering operations, but in a sense provides the user
with the ‘promise of objectivity’, as Gillespie recently put
it.[^5] It is no accident that the search result page –
designed to be visibly free from any imposed frame – is visually very
different from Google News, which on the contrary shows a very crowded
page, full of information, images, and so forth.[^6]
According to a Pew survey, 68 percent of users consider search engines
as an 'unbiased source of information', and 62 percent of them are not
capable of distinguishing between 'paid and unpaid results': for some
reasons, people simply tend to 'trust search
engines'[^7] while no longer trusting traditional news
media, and this attitude is arguably destined to give Google particular
strength.

Does the problem ultimately rely on the software, or the people using
it? According to the surveys focused on search engines, the web user –
far from being *engaged*, as she is too often supposed to be – assumes a
very *lazy* attitude. Most users, for example, only type a *one-word*
query,[^8] and very rarely combine more than three
words,[^9] in this way reducing complexity and limiting
themselves to the minimum cognitive effort. Confirming other studies,
Jansen, Spink, and Pedersen showed that most people usually dedicate no
more than five minutes to a web search and, in so doing, tend to select
nothing but the most common tools.[^10] In other
words, if search engines are, as stated years ago by Paul di Maggio et
al., ‘biased in their identification and, especially, ranking of sites,
the effects of this bias are compounded by the tendency of engine users
to employ simple search terms and to satisfice by terminating searches
at the first acceptable site’.[^11]

Further, surveys show a more relevant tendency dealing with the way
people normally receive and filter information. Between 60 and 80
percent of users read only the first ten results proposed by the search
engine, and data vary marginally between surveys, making their general
meaning clear. Those surveys are focused on the general use of search
engines rather than on Google as a specific service, however they tell
us something very important: people choose between *the first five or
ten links* selected by the algorithm, which are, according to the
original project, the most linked rather than the most reliable.
Consider Larry Page and Sergey Brin’s 1998 presentation of Google:

> Academic citation literature has been applied to the web, largely by
> counting citations or backlinks to a given page. This gives some
> approximation of a page’s importance or quality. PageRank extends the
> idea by not counting links from all pages equally, and by normalizing
> by the number of links on a page.

And the following ‘justification’ is that,

> Intuitively, pages that are well cited from many places around the web
> are worth looking at. If a page was not high quality, […] it is quite
> likely that Yahoo’s homepage would not link to it. PageRank handles
> both these cases and everything in between by recursively propagating
> weights through the link structure of the web.[^12]

*Some approximation*, *intuitively*, *quite likely:* PageRank can
possibly work as an indicator of quality – *possibly*, but this is not
its main goal. PageRank’s quantitative bias is not a well-kept secret;
this is generally the way Google works, and there is nothing bad in
quantitative methodology as such. The problem is not that Google
arbitrarily selects information, in this way establishing a cultural
(and hence political) hierarchy. The problem is that this ranking is not
perceived as arbitrary as it is, and has recently become a kind of
universal and well-established hierarchy. The most striking aspect of
the problem is that users only read the first results
page,[^13] therefore basically *validating* without
question the hierarchy arbitrarily established by the algorithm.
Consequently, PageRank is ‘recursively propagating’ its bias and leading
people to conform to what all the others are reading and (arguably) to
take this as a given. As for the exact percentage of people who only
read the first results page, data are not entirely consistent but are
enough to allow some confidence in the findings: 70 percent in a 1999
study,[^14] 58 percent in a 2000 survey focused on
Excite,[^15] 73 percent in a 2002 survey dedicated to
nine different search engines,[^16] more than 72
percent in a 2005 research on AltaVista.[^17] Though
clearly data vary, they account for the large majority of web users. If
we look at more recent surveys, we can find some partial confirmations
of previous tendencies. According to Jansen and Spink, web users are
'unwilling to invest additional effort to locate' relevant contents, and
still show a 'low tolerance of viewing any results past the first
page'.[^18] Statistical data released by Bing in 2013
show that 50 percent of users simply click the top result, while only
'4-6 percent click the third result'.[^19] On the
other hand, Keane, O’Brien and Smyth provided an empirical test by
simulating a Google interface able to reverse the order of results, thus
showing how people’s search is 'partially biased', even though users are
sometimes able to detect the most relevant page even at the bottom of
the list. [^20] In other words, the degree to which
the use of search engines is biased is still to be proved. The bias,
however, exists, since users are barely aware of the way algorithms
filter data and direct operations.

Unfortunately, the most part of available data reported in this article
are too old to provide a clear understanding of the current use of
search engines; however, they can help us raise some questions. What do
they suggest? Simply and sadly, that often people do not see any reason
to challenge search engines, or question their reliability and
transparency. If we consider that people now limit their consumption to
*one* search engine, the problem suddenly becomes evident.

##Google as Social Pattern

I said earlier that people use only Google and so do I, but is this
happening by accident or design? The reason why everybody uses Google
could actually be simple: Google provides the most reliable results. We
may however wonder to what extent such a universal usage ultimately
depends on a clear understanding of technical performances – which
should be based on a systematic comparison between *different* search
engines – or rather on the pressure of current cultural frames. In this
respect, we may wonder whether Google has been achieving dominance over
its competitors through a two-step process. At a first level, quality
arguably played a part: Google is considered to provide more complete
and spam-free results than its competitors, and people prefer it over
other search engines because of its accuracy and overall
quality.[^21] What is more, the fact that Google is
set as a default home page in some popular browsers has probably
contributed to its universal adoption, or at it least to the
consolidation of its leadership. For these reasons, it is actually
difficult to distinguish between technical and social factors when it
comes to analyzing their consequences on daily life practices. A social
pattern, wrote Pierre Bourdieu, is basically a form of ‘habitus’:

> a system of durable, transposable dispositions, structured structures
> predisposed to function as structuring structures, that is, as
> principles of the generation and structuring of practices […] which
> can be adapted to their goals without presupposing a conscious aiming
> at ends or an express mastery of the operations necessary to attain
> them […].[^22]

Could things have gone differently? Obviously yes, but this is how
social habitus works: as a piece of ‘history turned into nature’,
explains Bourdieu, by which the class structure governs real practices
through the mediation of a cultural scheme, able to engender ‘all the
thoughts, all the conditions, all the actions consistent with those
conditions, and no others’. As a consequence, people are forced to make
a virtue out of necessity, ‘at the cost of double negation’, that is,
‘to refuse what is anyway refused and to love the
inevitable’.[^23] Was Google necessary? I do not know.
Could people even *imagine* a Google-free life? Arguably no, or at least
I don’t think so. *Double negation*, in Bourdieu’s explanation, means
that you cannot desire something different from what the system wants
you to desire, and now you cannot perceive as real something which is
not included in Google. It seems that search engines eventually pass the
test of an ontological proof.

In the end, the main difference between traditional and algorithm-driven
media is this: all traditional media are each obviously biased, and this
is arguably why audiences no longer trust them. As Manuel Castells
pointed out, all recent international polls have been showing a very
similar trend, according to which people barely believe in political
parties, newspapers, and broadcasting media, all reported to be part of
the same influential lobby. According to Castells, this dissatisfaction
with traditional media is a first step toward discovering ‘mass self
communication’: people *have* to get rid of TV, so as to explore the new
possibilities opened up by the web.[^24] But this time
Castells is simply wrong, in my opinion. People do not believe in TV
anymore, but they *do trust* Google, and his almost naïve distinction
between ‘vertical’ and ‘horizontal’ media does not provide a serious
understanding of power as it is now taking place within the new digital
platforms.

##The Bubble Will Have You

PageRank is simply the first stage in Google’s strategy. The second is
characterized by the customization strategies through the use of
cookies, most likely launched in 2007 after the acquisition of digital
marketing company DoubleClick. The reasons behind this new strategy are
difficult to discern: arguably, the limits of the traditional business
model, which were only based on advertising revenues, played a part. In
fact, for some time and especially before its stock went public, market
conditions allowed Google to gather wealth by simply exploiting
advertising links; however, a new problem arose when technological
innovation finally promised web users the ability to skip the ad
links.[^25]

In this sense, the massive use of cookies can be intended as a more
narrow strategy to occupy the market: according to Eli Pariser, cookies
allow Google to ‘extrapolate what you like’, and shape the search
results according to your individual traffic history. More importantly,
Google is now ‘filtering out’ all the information that is not supposed
to be relevant for the target. Better yet, it is filtering out the
information that is not relevant according to what the user has done *in
the past*, in this way giving shape to an inherently static and
*conservative* culture. The result of this customization practice is a
‘bubble’, a kind of *cage*, in which individuals experience a particular
version of reality, different from that perceived by
others.[^26]

To some extent, one could say, we have always been living in a ‘bubble’.
Any mass medium – newspaper, television, etc. – provides a biased
representation of reality, and thus in turn builds a kind of bubble,
preventing its users from reading or watching all dissonant content.
This is of course true, even though Google’s bubble is more dangerous,
according to Eli Pariser, because it takes place at a very deep and
hidden level, characterized by three main differences: it is narrow,
invisible, and, what is more, almost impossible to avoid. ‘You are alone
in the bubble’, he writes, it being built upon individual rather than
collective preferences, and dedicated to a single consumption history
rather than to a community, such as the audience of a TV channel. On the
other hand, the new bubble is invisible: the framing operated by
traditional media can be ambiguous, but at its first level you obviously
*know* that you are accessing a given information environment, ruled by
a given gatekeeper. Conversely, in the new bubble the user is no longer
aware, for the cookies act at a very hidden level, such that you do not
even know that cookies *exist*. For the very same reason, in the end the
web user cannot decide to ‘enter the bubble’, as we do when choosing a
magazine, radio station, or a movie. The bubble is choosing the user and
surrounding his or her daily practices.[^27]

Both PageRank and cookies reveal that Google *does* indeed filter
information, in this way falsifying the ‘filter failure’ thesis
suggested by David Weinberger[^28] (and, in different
words, by Clay Shirky[^29]). According to Weinberger,
the web is not properly affected by a serious overload, but rather a
weakening of filters. It is this weakness of filters – which no longer
filter out, according to his optimistic idea – that is simply showing
the long forgotten state of our culture, that is, a disproportion
between individual comprehension, on the one hand, and knowledge as a
whole, on the other. Things are too big to know, Weinberger suggests,
and the web simply reveals this well-kept secret; but in any case the
idea that the new platforms simply filter forward and do not filter out
is hardly suitable for the way algorithm works, and it is entirely wrong
if we consider the deep effects of customization practices.

After PageRank and cookies, the next level is constituted, not by
accident, by a kind of hybrid form likely to implement social network
functions (Google+) in the search engine system. From the web at large
to the personal network: this narrowing of cultural horizons can come as
a surprise, but it is hardly unexpected if we consider that Google *does
not trade information*, as it claims it does, but something very
different. In a complex cultural system, as Tiziana Terranova recently
noted, the true traded value is no longer information, but *attention*.
While in fact the first is too widely available, the latter is under a
scarcity regime, and is the ideal ‘condition that can give rise to a
proper economy’.[^30] Therefore, ‘technology of
attention’ is a good definition for what Google, along with other
players, is now doing – gathering and trading people’s attention, and
even reducing its information flow (to a great extent, attention for
attention’s sake: the use of personal data is actually not as important
as its control and storage). Or, as Rachael – *Blade Runner*’s most
controversial replicant – famously said: I am not in the business; I
*am* the business.

Page and Brin’s famous paper only describes the first stage in the
evolution of Google, but we know that its functioning cannot be reduced
to PageRank: its algorithms are actually based ‘on more than 200 unique
signals’, including ‘the freshness of content’ and the user's region.
[^31] In the last years, Google has released many new
features, such as ‘social search’, designed to ‘understand not only
content but also people’, and allow users to find information directly
related to them; [^32] ‘knowledge search’, which
introduces some elements of the so-called ‘semantic web’;
[^33] and Google Now, a service expected to provide
you with the right information ‘before you even ask’, through the
implementation of geo-locative technologies. [^34] In
short, Google combines many different services and tools, but I here consider only two of them – PageRank and the use of cookies – which
seem to produce the most interesting effects. While the PageRank
algorithm tends to favor the most linked pages, thus building a kind of
homogenized agenda of knowledge and information, the use of cookies on
the contrary leads to a very specific customization, likely to provide
any user with a sort of individual ‘bubble’. So cookies oppose the
tendency of PageRank, insofar as cookies model search results after the
user’s individual tastes and preferences, which can be automatically
detected. Google’s action is therefore splitting into two different and
almost opposite tendencies: the maximum degrees of standardization and
individualization, which becomes quite a challenge for social studies.

##Dialectic of Google

I’ve said the maximum degrees of standardization and individualization
coexist in the same device. This seems to confirm Geert Lovink’s idea
that in the stage of mass web diffusion there would no longer be a
dominant tendency, whether we look for positive or negative effects of
the internet.[^35] But there is something more here.
What emerges is in fact a new technical version of the most traditional
sociological problem, the tension between individual and structure, and
the rise of a new order, regulating the relationship between the two.

The role played by media and cultural industries in maintaining this
balance has been widely investigated. In particular, Adorno and
Horkheimer made a critical analysis in their *Dialectic of
Enlightenment*:

> The sociological theory that the loss of the support of objectively
> established religion, the dissolution of the last remnants of
> precapitalism, together with technological and social differentiation
> or specialization, have led to cultural chaos is disproved every day;
> for culture now impresses the same stamp on
> everything.[^36]

Even 70 years after Adorno and Horkheimer’s masterwork, this point
remains: the idea according to which the evolution of our societies will
eventually destroy all solid structures and lead to a kind of cultural
chaos is simply ‘disproved’ by fact. According to Adorno, capitalist
culture is stable (the ‘rhythm of the iron system’) rather than fluid,
or, as we would say in present terms, post-modern or liquid. As Franco
Moretti recently pointed out, Western bourgeoisie has actually been
historically functioning as a conservative *force*, so as to normalize
social turbulence, and build up a predictable pattern of everyday life –
and ‘all that was solid’ eventually ‘became more
so’.[^37] At the same historical end, it seems that
Google is stressing this tendency to its limits, ‘now impressing the
same stamp on everything’ – *everything*: news and general contents,
books and geographical maps, social circles and e-mail services, and so
on. Two opposite and *dynamic* tendencies that nonetheless cooperate to
produce a *static* result: the ‘inherently conservative’ nature of
Google’s cultural processes by which, as discussed by Eli Pariser and
Siva Vaidhyanathan, anyone will basically find what he or she is inclined
to look for, and will eventually know what he or she already knows. The
bubble, in this sense, is the ultimate technical version of a long-term
process by which the individual has become a predictable part of a
predictable statistical pattern:

> Everybody must behave (as if spontaneously) in accordance with his
> determined and indexed level, and choose the category of mass product
> turned out for his type. Consumers appear as statistics on research
> organization charts […]. The technique is that used for any type of
> propaganda.[^38]

Therefore, the individual bubble, the homogeneous global agenda, and the
tension between the two factors can be regarded, to a considerable
extent, as a tension of opposites. But do we really need such a
complicated explanation as a *dialectic* of Google? More consideration
needs to be given to three aspects of Google’s hegemony: the search
algorithm, the contradiction between PageRank and the customization
strategies, and finally the dynamic evolution of both tools.

PageRank obviously relies on *quantity*: the more links you have, the
higher you will rank according to the algorithm’s hierarchies. We know
what logically follows is the power law nature of the web: links, as
almost any other resource, tend to cluster around a handful of sites,
following the ‘80/20 rule’ of the Pareto
principle.[^39] In this sense, PageRank is neither
establishing nor questioning a ranking, while the algorithm simply
reproduces a previous hierarchy. This is why, following Vaidhyanathan,
Google’s power has less to do with cultural than ‘infrastructural’
imperialism – the production of ideological content, or public opinion
shaping, versus the control of the communication *process*as
such.[^40] However, during this process, something is
happening: quantity is definitely turning into *quality*, and for the
very same reason – content does not matter, only links do. This tendency
can be labeled simply as ‘the transformation of quantity into quality
and vice versa’.

We’ve seen that this standardization tendency is counter-balanced by a
different process, enabled by the use of cookies: a very narrow
customization strategy, likely to build up a bubble around any
individual profile. But the point I am most interested in is that
Google’s inner process is not exhausted by either tendency, but is made
of both, however contradictory they may be. Search results are organized
according to the individual footprints detected by cookies, but
ultimately rely on the same, common, *sterilized* cultural universe. Two
opposite forces in the very same device – in other words, a kind of
‘interpenetration of opposites’.

However, this is not a static contradiction but a mobile tension,
wherein any innovation is not just an advancement of a previous
technology, but its overcoming through the exploration of a new
evolutionary path. The PageRank algorithm, for example, is said to make
the world too homogenous, with cookies now providing the opposite
effect. Though Google can be blamed for destroying the copyright system
and even the humanistic heritage as a whole, Google Books will
eventually save it. We must still keep in mind all the polemics of the
‘virtual’ world and its likely effects on the representation of reality,
as when Google Maps suddenly provides a hybrid representation of the
planet, half ‘real’ and half ‘virtual’. Any process is a negation of the
previous one, leading the system to a temporary equilibrium, destined in
turn to give new transformation a place. Perhaps we could define this
phenomenon with Hegel’s words: the ‘negation of negation’.

I will stop here, as I have attempted, in a half serious way, to apply
Friedrich Engels' laws of dialectics to Google’s cultural
system.[^41] *Serious*, because I think that current
technological innovation does require a strong theoretical investigation
rather than a merely quantitative analysis usually operated through
crawlers (which, in a sort of vicious circle, provide a further
legitimation of commercial software as the only valuable cultural
platform, and so on). *Half* not serious, because I am not actually
sure that the traditional forms of thought – such as Engels' dialectics,
or Bourdieu’s view of social practice – are the most suitable ones for
the current needs of critical theory.

Absolutely, though, the two forces acting behind Google reproduce the
basic tension between individualization and standardization that any
social system is made of, while, at the same time, they move it to a
next evolutionary level. What kind of sovereignty are we talking about
with the homogenization of global knowledge and the ‘micro-physical’
customization of digital marketing? Put in different terms: cookies
collect data in a cultural ecosystem where, for good or for bad, such
things as violence, pornography, multiple names, anonymity (in a word,
*dissonance*) have been banned. In this context, the individual is a
consumer, tracked with any move he or she makes, and living in a
digital market where there is no room for conflict. What a powerful
device, and what an ideal habitus for the world order of late
capitalism.

##References {.references}

Adorno, Theodor and Max Horkheimer. *Dialectic of Enlightenment* (1944),
London: Verso, 1997.

Barab á si, Albert-Laszlo. Linked: The New Science of Networks , New
York: Perseus, 2002.

Barzilai-Nahon, Karine. 'Toward a Theory of Network Gatekeeping: A
Framework for Exploring Information Control', *Journal of the American
Society for Information, Science and Technology* 59.9 (2008): 1493-1512.

Bourdieu, Pierre. *Outline of a Theory of Practice*, Cambridge:
Cambridge University Press, 1977 (1972).

Brin, Sergey, and Larry Page. 'The Anatomy of a Large-Scale Hypertextual
Web Search Engine', Seventh International World Wide Conference,
Brisbane, 1998, http://ilpubs.stanforde.edu:8090/361/.

Castells, Manuel. *Communication Power*, Oxford: Oxford University
Press, 2009.

Di Maggio, Paul, Eszter Hargittai, W. Russell Neuman, and John P.
Robinson. 'Social Implications of the Internet', *Annual Review of
Sociology* 27 (2001): 307-336.

Engels, Friedrich. *Dialectics of Nature*, Minneapolis and St. Paul:
Wellred, 2012 (1883).

Fallows, Deborah. ‘Search Engine Users. Internet Users are Confident,
Satisfied and Trusting – but They Are also Unaware and Naïve’, Pew
Internet & American Life Project, 2005.

Gillespie, Tarleton. 'The Relevance of Algorithms', in Tarleton
Gillespie, Pablo Boczkowski, and Kirsten Foot (eds), *Media
Technologies*, Cambridge, MA: MIT Press, forthcoming.

Jansen, Bernard, and Amanda Spink. 'How We Are Searching the World Wide
Web? A Comparison of Nine Search Engine Transaction Logs', *Information
Processing and Management* 42 (2006): 252-256.

Jansen, Bernard, Amanda Spink, and Jan Pedersen. 'A Temporal Comparison
of AltaVista Web Searching', *Journal of the American Society for
Information, Science and Technology* 56.6 (2005): 559-570.

Jansen, Bernard, Amanda Spink, and Tefko Saracevic. ‘Real Life, Real
Users, and Real Needs: A Study and Analysis of User Queries on the Web’,
*Information Processing and Management* 36.3 (2000): 207-227.

Keane, Mark, Maeve O’Brien, Barry and Smyth. ‘Are People Biased
in Their Use of Search Engines?’, *Communications of the ACM* 51.2
(2008): 49-52.

Lovink, Geert. *Zero Comments: Blogging and Critical Internet Theory*,
New York: Routledge, 2007.

Moretti, Franco. *The Bourgeois between History and Literature*, London:
Verso, 2013.

Pariser, Eli. *The Filter Bubble. What the Internet Is Hiding from You*,
New York: Penguin, 2011.

Shirky, Clay. *Cognitive Surplus. Creativity and Generosity in a
Connected Age*, New York: Penguin, 2010.

Silverstein, Craig, Monica Henzinger, Hannes Marais, and Michael Moricz.
'Analysis of a Very Large AltaVista Query Log', Newsletter ACM SIGIR
Forum, 33.1 (1999): 6-12.

Spink, Amanda and Bernard Jansen. 'A Study of Web Search Trends',
Webology 1 (2004), [www.webology.ir](http://www.webology.ir/) .

Terranova,**Tiziana. 'Attention, Economy and the Brain', *Culture
Machine* 13 (2012): 1-19.

Vaidhyanathan, Siva. *The Googlization of Everything (And Why We Should
Worry)*, Berkeley and Los Angeles: University of California Press, 2011.

Vise, David, and Mark Malseed. *The Google Story*, New York: Random
House, 2005.

Wang, Peiling, Michael Berry, and Yiheng Yang. 'Mining Longitudinal Web
Queries: Trends and Patterns', *Journal of the American Society for
Information Science and Technology* 54.8 (2003): 743-758.

Weinberger, David. *Too Big to Know*, New York: Basic Books, 2011.

##Notes {.notes}

[^1]: Data available at www.comscore.com.

[^2]: Data available at www.fullplan.it.

[^3]: Siva Vaidhyanathan, *The Googlization of Everything (And Why We
    Should Worry)*, Berkeley and Los Angeles: University of California
    Press, 2011, p. 144.

[^4]: Karine Barzilai-Nahon, ‘Toward a Theory of Network Gatekeeping: A
    Framework for Exploring Information Control’, *Journal of the
    American Society for Information, Science and Technology* 59.9
    (2008): 1493-1512.

[^5]: Tarleton Gillespie, 'The Relevance of Algorithms', in Tarleton
    Gillespie, Pablo Boczkowski, and Kirsten Foot (eds) *Media
    Technologies*, Cambridge, MA: MIT Press, forthcoming.

[^6]: See David Vise and Mark Malseed, *The Google Story*, New York:
    Random House, 2005.

[^7]: Deborah Fallows, ‘Search Engine Users. Internet Users are Confident,
    Satisfied and Trusting – but They Are Also Unaware and Naïve’, Pew
    Internet & American Life Project, 2005, p 15.

[^8]: Bernard Jansen and Amanda Spink, ‘How We Are Searching the World
    Wide Web? A Comparison of Nine Search Engine Transaction Logs’,
    *Information Processing and Management* 42 (2006): 252-256; see also
    Peiling Wang, Michael Berry, and Yiheng Yang, ‘Mining Longitudinal
    Web Queries: Trends and Patterns’, *Journal of the American Society
    for Information Science and Technology* 54.8 (2003): 743-758.

[^9]: Bernard Jansen, Amanda Spink, and Tefko Saracevic, ‘Real Life, Real
    Users, and Real Needs: A Study and Analysis of User Queries on the
    Web’, *Information Processing and Management* 36.3 (2000): 216.

[^10]: Bernard Jansen, Amanda Spink, and Jan Pedersen, ‘A Temporal
    Comparison of AltaVista Web Searching’, *Journal of the American
    Society for Information, Science and Technology* 56.6 (2005):**564.

[^11]: Paul Di Maggio, Eszter Hargittai, W. Russell Neuman, and John P.
    Robinson, ‘Social Implications of the Internet’, *Annual Review of
    Sociology* 27 (2001): 314.

[^12]: Sergey Brin and Larry Page, ‘The Anatomy of a Large-Scale
    Hypertextual Web Search Engine’, Seventh International World Wide
    Conference, Brisbane, 1998, http://ilpubs.stanforde.edu:8090/361/.

[^13]: See Craig Silverstein, Monica Henzinger, Hannes Marais, and Michael
    Moricz, 'Analysis of a Very Large AltaVista Query Log', *Newsletter
    ACM SIGIR Forum* 33.1 (1999): 6-12.

[^14]: Amanda Spink and Bernard Jansen, ‘A Study of Web Search Trends’,
    *Webology* 1 (2004), www.webology.ir.

[^15]: Jansen, Spink, and Saracevic, 'Real Life, Real Users, and Real
    Needs', p. 215.

[^16]: Jansen and Spink, 'How We Are Searching the World Wide Web?', pp.
    257-258.

[^17]: Jansen, Spink, and Pedersen, 'A Temporal Comparison of AltaVista Web
    Searching', p.**563.

[^18]: Jansen and Spink, 'How Are We Searching the World Wide Web?' p. 260.

[^19]: Data available at
    http://www.bing.com/blogs/site\_blogs/b/searchquality/archive/2013/04/24/ten-blue-links-no-more-dynamic-page-sizing.aspx.

[^20]: Mark Keane, Maeve O’ Brien, and Barry Smyth, ‘Are People Biased in
    Their Use of Search Engines?’ *Communications of the ACM* 51.2
    (2008): 49-52.

[^21]: Fellows, *Search Engine Users*, p. 14.

[^22]: Pierre Bourdieu, *Outline of a Theory of Practice*, Cambridge:
    Cambridge University Press, 1977 (1972), p. 78.

[^23]: Bourdieu, *Outline of a Theory of Practice*, p. 77.

[^24]: Manuel Castells, *Communication Power*, Oxford: Oxford University
    Press, 2009.

[^25]: See Vise and Malseed, *The Google Story*.

[^26]: Eli Pariser, *The Filter Bubble. What the Internet is Hiding from
    You*, New York: Penguin, 2011.

[^27]: Pariser, *The Filter Bubble*, pp. 9-10.

[^28]: David Weinberger, *Too Big to Know*, New York: Basic Books, 2011.

[^29]: Clay Shirky, *Cognitive Surplus. Creativity and Generosity in a
    Connected Age*, New York: Penguin, 2010.

[^30]: Tiziana Terranova,*'*Attention, Economy and the Brain', *Culture
    Machine* 13 (2012): 2.

[^31]: See,
    http://www.google.com/intl/en/insidesearch/howsearchworks/algorithms.html.

[^32]: See,
    http://googleblog.blogspot.it/2012/01/search-plus-your-world.html.

[^33]: See,
    http://www.google.com/insidesearch/features/search/knowledge.html.

[^34]: See, http://www.google.com/landing/now/.

[^35]: Geert Lovink, *Zero Comments: Blogging and Critical Internet
    Theory*, New York: Routledge, 2007.

[^36]: Theodor Adorno and Max Horkheimer, *Dialectic of Enlightenment*,
    London: Verso, 1997 (1944), p. 120.

[^37]: Franco Moretti, *The Bourgeois Between History and Literature*,
    London: Verso, 2013, p. 15.

[^38]: Adorno and Horkheimer, *Dialectic of Enlightenment*, p. 123.

[^39]: Albert-Laszlo Barab á si, Linked: The New Science of Networks , New
    York: Perseus, 2002.

[^40]: Vaidhyanathan, *The Googlization of Everything*, pp. 110-114.

[^41]: See Friedrich Engels, *Dialectics of Nature*, Minneapolis and St.
    Paul: Wellred, 2012 (1883).



