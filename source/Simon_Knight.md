---
Title: "Finding Knowledge: What Is It to ‘Know’ When We Search?"
Author: Simon Knight
---

>*You walk into the exam room, breathe a nervous sigh, sit down, and plug
your laptop in. The URL for the questions is sent out, and you are
reminded that while you may search for information and browse pages as
you wish, you may not communicate with any other person. You look at the
first question; it gives you a poem from an author you know little
about, along with some brief historical context, and another source you
have studied before. You are asked to draw comparisons between the
perspectives of the sources, using your knowledge of the period.
‘Right,’ you think, as you open up a popular search engine, ‘what do I
need to know…’*

Consider the preceding vignette; Andy Clark and David Chalmers propose
that in such cases the external apparatus (the internet) fulfills the
same functional role as the internal apparatus (the brain) and thus
should be considered an extension of our mind.[^1] For
the purposes of this essay readers need not 'buy into' the extended mind
thesis whole scale. Rather, this example is intended to illustrate a
general point regarding the relationship between technology and the
mind: When analyzing the functional role of technology we should
consider how it shapes our activities, its implications for epistemic
concepts such as 'knowledge', and the differences between pre- and
post-technology practices.

Such an analysis has profound implications in education, for example.
Under what circumstances do we accept that students ‘know’ something?
How do we decide that they know something (that is, how do
educators claim knowledge of their student’s knowledge states) and also
that such knowledge is important? Furthermore, how do we think about the
future of technology and the ways that technology might change what we
believe is important (for better or worse)?

Indeed, the issue of external tools is not an abstract problem. Open
book exams have existed for some time, as have ‘take home’ exams and
coursework. Moreover, in Denmark a three-year trial – now implemented –
started in 2009 to permit the use of the internet in exams.
[^2] The inclusion of the World Wide Web in examinations
(excluding sites which could be used to communicate with other students)
was a natural extension of earlier Danish examinations that had included
multimedia resources ranging from CD-ROMs to videos, audio, and
webpages. The aim was to give students the opportunity to work with a
variety of resources and to probe analysis**skills and metacognitive
skills, such as checking mathematical outputs using multiple methods.

I find the Danish example particularly interesting because it is so far
removed from what my own assessment experience has been – both as a
teacher and student. Moreover, as I and others have argued, our
assessment methods implicate particular epistemological assumptions;
measuring ‘knowledge’ of unconnected ‘facts’ suggests a rather different
way of thinking about knowledge than those that require testing the
filtering and analysis of resources towards some critical, evaluative
output. The epistemological implications of our social and technical
interactions with information is the subject of this essay. I will
specifically look at the role of search engines as informants offering
testimonial knowledge on a query, then at the question of how the
receiver of testimony should be taken into account by those giving the
information, and finally at how we should deal with multiplicity of
perspectives, or even gaps in our knowledge.

Of course, the simple retrieval of precise information on the internet
may be a challenge for many. Readers may recognize the experience of
having a friend or colleague ask a question, which you respond to by
turning to a search engine and finding an answer to the request with the
first query. Indeed, the website www.lmgtfy.com – ‘let me google that
for you’ – exists for that purpose, animating a search for any given
query. The Danish example, though, shows that it is still required for
students in this case to remember (‘know’ according to some)
information, while still allowing them to engage critical literacy
skills to connect pieces of information from across multiple web
sources.

As mentioned above, we should examine the implications of technology
concerning how we think and how our activities are shaped. However, we
should not assume *prima facie* that these technological changes
actually represent new epistemologies, whether positive or negative, nor
new ways of thinking about what it means to ‘know’. Rather, we should
seek to understand the nature of ‘knowledge’, and how informants –
including non-human informants – mediate our understanding of the world
around us and have always done so. This essay considers these questions,
first by discussing some issues regarding research on technological
changes, then by asking what role search functions fulfill and how these
functions affect our own understanding of ‘knowledge’.

##Researching Search

The impact of the internet on how we think has caught popular attention
in the many articles – often critical.[^3] However, many
of these articles assume that change is a bad thing – particularly any
indication of neurological change – and they often report studies of
very particular circumstances. Yet neurological change is unsurprising
given the human brain’s high plasticity, and it is incredibly difficult
to conduct solid research that tracks abilities over time given the
challenges to control across multiple cohorts of ages and educational
systems.

Much of the substance of these debates boils down to what we value. We
have previously valued memory and memorization of facts, in part because
they are easy to assess.[^4] However, presumably most
people would agree that the purpose of education is not the speedy
recall of facts – it is not to develop world-class pub quizzers, capable
of reciting the dates of monarchy. Instead, the idea behind assessments
is that if students can recall facts, then – by proxy – they have
knowledge about those facts, meaning they can engage with critical
skills of evaluation, etc. Fundamentally, these skills – understanding
the connectedness of knowledge, of evaluation, of making credibility
judgments – are what knowledge consists of, not the recall of individual
‘facts’ in constrained contexts. Critical skill is also what the Danish
system seeks to measure; given the easy access to facts through search
engines, a focus on synthesis and evaluation becomes easier. However,
the question of how the tools help shape our thinking still stands. Just
as books, with indexes, chapters, reference lists, and so on, present
information in certain ways, so too does the internet and its tools of
access, such as search engines, browsers, and social network sites.

##Search Engines as Informants

An interesting aspect of the Danish example is the prohibition of
communication websites in examinations. Yet the line between search
engines and social networking sites is increasingly blurring. Indeed,
while Google's advertising rhetoric has tended to focus on a desire to
‘know what you want, before you do’,[^5] Bing (with
Facebook), at least in North America, has developed ‘Bing
Social’[^6] with the headline: ‘For every search, there
is someone who can help.’

Google’s strategy is to use developments in semantic web technology to
identify key facts associated with any particular query; thus, a search
for Florence Nightingale brings up a standard search engine results page
(SERP) with key links on it. However, in addition to that SERP, there is
a box on the right hand side with some key facts about Florence
Nightingale populated from her Wikipedia entry. Bing Social, in
contrast, uses similar developments in social network data to infer
whether someone might be a good ‘informant’ for any particular query –
for example, whether or not that person has qualifications in the
subject of historical figures. Thus Google’s Knowledge Graph has been
developing more as a direct informant – providing the information itself
– while Bing Social (and Facebook Graph search) aim to provide you with
good informants from your social network.

Both of these approaches have obvious uses and advantages but also
potential problems. Examples of the risks of seeking informants in one’s
own social network (the Bing Social and Graph Search approach) are:

-   If your social network mediates your information seeking, there is
    likely to be a confirmation bias in the returned results. If our
    results are influenced by our friendship groups (particularly biased
    in ways we might not be aware of), this raises serious concerns
    about the epistemic properties of the search, which we might expect
    will return both all relevant results (recall), and specific results
    that meet the criteria we have stated (precision).
-   The above concern is particularly true for those who do not (or who
    rarely) use the internet – both in terms of an offline searcher’s
    access to information, and in terms of an online searcher’s access
    to information about those offline.
-   Such data is likely to be *messy*– many people may not want all
    facets of their life to be searchable (indeed, there’s a Tumblr for
    that[^7]); plenty of people post information to
    their social networks that might make them prominent in search
    results, but not necessarily good informants. For example they
    ‘like’ pages for signaling some attribute they don’t actually have,
    or to get discounts from brands, or to monitor activity (e.g.
    watching a political opponent’s activity).

Two key ideas from the work of philosopher Miranda Fricker strike me as
particularly fruitful here,[^8] and to my knowledge they
have not yet been explored in this context:

-   The risk of *testimonial injustice* – the risk that some types of
    user knowledge will be marginalized by specific agents on the basis
    of their (demographic or personal) characteristics. Whether such a
    risk is greater or lesser in a particular search (or recommender)
    system is an interesting question (and might be thought of as a case
    of prejudice exercised by individuals).
-   The risk of *hermeneutical injustice*– the risk that some types**of
    user knowledge will be marginalized by the system, perhaps in such a
    way as to make those users unaware of their own epistemic injustice.
    Again, whether such a risk is greater or lesser in particular search
    (or recommender) systems is interesting. (This risk might be thought
    of as a case of marginalization, as opposed to explicitly enacted
    prejudice.)

These problems are arguably a part of the more general problem of the
filter bubble: the concern that search engines through personalization
and demographic characteristics filter SERPs to provide individuals with
biased information, affirming prior beliefs. It is to this issue that I
now turn.

##Search as an Epistemic Tool – More of What You Want

The use of search engines to find information or sources of information
is a common activity in which students must frequently engage. In a 2012
paper, Thomas Simpson suggests search engines fulfill the role of
‘surrogate experts’, and that we should be concerned about their
epistemic properties – their ability to return relevant results
(precision), not exclude relevant results (recall), return results in a
timely manner, and prioritize credible sources.[^9] In
particular, they should be ‘objective’. By this he means that if two
sides to a story exist and are equally linked to across the web, then
they should be interleafed and not stacked. SERPs should not present a
biased perspective on credible sources.

However, Simpson and various other authors argue that personalization of
search results fails this ‘objectivity’ criterion. His claim is that
presenting information that is likely to affirm a user's prior beliefs
is problematic because – unless the individual is an ‘epistemic
saint’[^10] – the search engine fails to represent the
domain being searched. Simpson suggests two solutions: first, turning
off personalization or querying search engines that do not use
personalization, and second, legal regulation of search engines'
objectivity.

While there are certainly valid concerns regarding this issue, here I
want to discuss some of the motivations for personalization and personal
recommendation (such as the Bing Social example discussed above) in
light of testimonial knowledge. In the context of filter bubbles we
should consider:

-   Searchers may well search for biased information in their queries –
    searching for ‘Al Gore inconvenient truth’ may bring up rather
    different results than ‘Al Gore liar’.
-   SERPs may present bias for two reasons:
    1. Bias will arise from personalization of results (this is broadly
    *testimonial injustice*).
    2. Bias will arise from an epistemically biased landscape – for
    example, language and gender dominance among Wikipedia articles and
    editors (this is broadly *hermeneutical injustice* and may be more
    challenging for search engines to address).
-   Social search is likely to present many of the same problems, but
    many non-personalized search engines will too.

It is worth considering the role of the search engine in epistemic
inquiry, and how search engines could foreground their assumptions about
searchers to fulfill their roles as informants.

##Testimonial Expertise

>*You’re conducting a school research project on a local Spanish festival
that happens to be a namesake of an English clothing brand. You ask your
parents for some useful websites on the festival; they give you the
details of a U.K. arts festival nearby, along with a link to a website
with a primary school level English description of the clothing brand…*

When we seek information we are interested in different things in
different contexts. One of the challenges of the ‘semantic web’ is to
understand the varied meanings that any particular word can indicate –
in short, to understand context. For that reason, some researchers began
talking about the ‘pragmatic web’, the development of technologies to
support language in action perspectives in order to understand how
queries might be *used*.[^11] Of course, in education
we also want to train people to care about the right things in the right
context.

The example given above highlights how irritating such ‘help’ could be;
similarly, while search engines rarely are true surrogate experts
(Knowledge Graph being a counterpoint), they do strive for quality by
pointing out good informants – that is, by testifying that a website is
a good source in the given context. We expect informants – human and
otherwise – to take into account salient factors about ourselves,
although we might expect some of these to be left implicit (e.g.
geolocation of information) but not others (e.g. political leanings, or
perhaps facets such as literacy level).

##Personalization

>*A search function returns English results, and when you check
quantities it defaults to metric, always using a base 10 numeric
system.* [^12] *When you search for your morning news,
a set of left-wing blogs you like to read are returned, along with a new
source and an article a friend of yours has recommended on a popular
social networking site.*

While certainly in the latter case the search engines’ complicity in
confirmation bias may be an issue, the real concern is the searcher’s
own epistemic standpoint and his or her openness to other perspectives
(which the search engine might be able to present the searcher with
while still highlighting recommendations). We should pay more attention
to the level of the *agent*when considering the filter bubble.

However, despite this claim, there are at least two major cases where we
can imagine filter bubbles in which the searcher is not complicit:

-   The ‘racist classmate’ case. In this example, we imagine a searcher
    who, without knowing, has a classmate who searches for white
    supremacist websites. In fact, we can imagine a more innocuous case
    in which the searcher’s classmate is particularly fond of one local
    café; unknown to the searcher, their searches are thus pushed
    towards that café as opposed to other – equally well liked,
    reviewed, and known – local establishments. The concern here is not
    that the search engine knows one's geolocation, but that by
    tailoring to repeated searches – while not making this explicit in
    the search interface – the SERP provides a non-objective set of
    results (this is true even if one’s own searches have developed the
    bias).
-   The ‘biased community’ case. In this example, we imagine a country
    where the majority of searchers are more inclined towards one
    perspective on an issue than another. Thus, despite the presence of
    credible, timely, and well-linked online resources from the other
    perspective, searchers in that country are more likely to be
    directed towards the majority perspective.

In both cases the search engine mediates our access to information in
ways that make understanding that information *less*transparent – they
thus fail to act as objective informants.

We can see that to some extent personalization is exactly what we expect
informants to deliver – I want information that understands my context.
However, I also want to be able to interrogate the informant's
understanding of my context, to ensure we are ‘on the same page’ as it
were, and in this respect search engines often fail. I would suggest
that personalization is bad not because it’s non-objective, but that,
when giving an ‘objective’ judgment of testimony, we expect informants
to tell us about the substantive assumptions they make in order to come
to their conclusions. We expect to have some shared understanding of the
assumptions informants make about our information needs. Search engines
often fail to offer this kind of disclosure, except when there is good
reason for them to do so (often advertising-based, for example asking
searchers to clarify their postal code for the purposes of geo-located
targeted advertisements). However, where these assumptions are explicit,
their impacts are often not made clear. I will now discuss another
example of the socio-technical mediation of our understanding of
information, before presenting a final challenge to the current status
quo.

##When No Answer Is Answer Enough

An interesting, related problem concerning how we think about
information comes in the form of the ‘testimony of silence’ – when the
absence of information informs you of something.[^13]
We can imagine this happening in a number of cases:

1.  When a searcher queries a search engine, receives no answers, and
    takes that to imply positive knowledge (e.g., searching for
    information on traffic jams and finding nothing, leading the
    searcher to believe there are no current traffic problems).
2.  When searchers seek information, receive no answer, and take that to
    mean poor community support or expertise (e.g. in the above example,
    assuming that no answer is due to a failure of technology, or in a
    scientific context thinking lack of an answer means there is no
    research on the topic searched).
3.  When people search for information and receive irrelevant answers
    (e.g. in the ‘bad informant’ example above, a search is conducted to
    find information on a festival, but the only results returned are
    about another concept).
4.  When people search for information but do not see the response (e.g.
    where search results are weighted against the answer they are
    looking for, as in some filter bubble cases above).

Again, in this context search engines, searchers, and the epistemic
environment all play a part in the state of knowledge. To give an
example of a complex case, I conducted a study in which I asked
11-year-old children in a classroom to find the answer to the question,
‘How many women have won The Nobel Prize?’[^14] This
query is relatively simple in many respects, and in fact simply entering
the query into most search engines will bring up a relevant result with
the correct answer. However, slightly to my surprise, some of the
children visited ‘answer’-style websites and took the user-submitted
claims made there without checking the date of the answer given, thereby
reflecting a lack of attention to the nature of change in such knowledge
claims. For other questions some children decided there was no answer
when they could not find one, failing to adjust their search terms or to
think about how other information might be relevant to their problem.
Educational contexts are further complicated by the presence of content
filters that can prevent students from seeing highly relevant results.

In each of these instances, search results' presentation and user
interaction have an impact. Users may be more likely to see information
that confirms their prior beliefs; this bias relates to their queries,
the results they click, and the information they take away from chosen
results. For example, recent evidence from Microsoft Research indicates
that in the health domain, searchers favor positive over negative
information *as do search engines*– thus creating a filter bubble based
on a ‘testimony of silence’ around negative results.[^15] Importantly, this bias leads to the uptake of incorrect health information in many cases.[^16]

##Diversity Aware Search

In the preceding sections I have noted some concerns over how we look
for information and why understanding the socio-technical factors
involved might be interesting. There are a number of suggested solutions
to these problems, but many have issues. For example:

-   One solution to the filter bubble is not to personalize results.
    However, this is problematic because, as discussed above, we expect
    a degree of personalization from good informants. We expect
    information to be in accord with our prior understandings, our
    context (geographic if nothing else), etc. However, search engines
    such as DuckDuckGo follow exactly this approach.
-   Another solution is to use friends and other social contacts as
    informants. Our friends understand our common knowledge and can
    address this and be interrogated as to their reasons more directly;
    of course, there are still important biases here, and my friends may
    not be able to inform me about a rather large range of topics.
    Moreover, often we don’t want our social contacts to know about our
    information needs in the first place.
-   Another solution is to show results deliberately that are beyond the
    area of enquiry, either topic-wise, socially, or in terms of
    perspective taken.

This last approach is interesting as it attempts to diversify
perspectives and contexts; it has been described as ‘Diversity Aware
Search’.[^17] As has been noted, ‘diverse exposure’
may be a means to burst your filter bubble, with methods ranging from
clustering results, depictions of the ‘balance’ of articles searchers
have actually viewed, and asking readers to engage in discourse based on
considering multiple perspectives. [^18] The ‘liquid
publications’[^19] project for example developed a
diversity-aware scholar search that can be used to avoid homophily in
one’s academic network by down-ranking papers by authors with whom the
searcher has co-authored in the past.

Other solutions could be to look for diverse ways of clustering the same
set of documents or present searchers with clusterings from different
users;[^20] this could particularly work in cases
where the user is ‘exploring’ the information landscape and has no
well-defined information need at initial stages. [^21]
In this case, searchers may be unaware of alternative groupings and**of
various ways their information need could be defined. Such approaches
may foreground facets of personalization that usually remain hidden.

An additional benefit of such diversity-aware search tools is that they
offer the opportunity to address ‘content holes’ in a searcher’s
knowledge. [^22] Indeed, such an approach may assist
in addressing some of the issues of ‘silence’ raised above. To give an
example taken from Nadamoto et al., we might imagine a Mexican community
in which swine flu in Mexico is widely discussed and
known.[^23] However, if that community does not also
relate to the wider global risk of swine flu, it has a content hole;
such gaps might be identified in community discussions across blogs
through comparisons with content on related Wikipedia pages.

It is interesting to note that such an approach might also lead to
unintended consequences, for example insofar as some research indicates
that exposure to opposing perspectives can reinforce one’s own
viewpoint (and prepare one for arguing against opposition).
Furthermore, technical approaches that increase diversity by reducing
redundancy (repetition of information) may lead a person to question an
important credibility cue, given that repetition may be highly salient
in the context of seeking to corroborate sources. Therefore
diversity-aware search is not a definitive solution to the problems
presented above, but rather an indication of a design feature that might
present interesting alternatives and lead to different interactions with
search users. A big problem of search engines that are not
diversity-aware is that the user will almost never learn how biased the
retrieved information is. It would help if search engines would state
what kind of filtering and interpretative steps they perform.

##Conclusions

>*You are asked to draw a comparison among the perspectives in the
sources, using your knowledge of the time. ‘Right’, you think, as you
open up a popular search engine, ‘what do I need to know…’*

Access to external resources prompts us to consider what it means to
‘know’ something and what types of knowledge are important. Asking you
what a ‘clepsydra’ is has a different connotation in a closed book or an
open (or internet-enabled) examination. That is not to say that
memorizing ‘facts’ has no value; it is sometimes rather important, for
example in the case of remembering road sign meanings. However, facts
aren’t disconnected from meaning, and exploring how people
*use*information gives insight into their knowledge states.

On the internet, the tools at hand provide paths to information, offer
particular routes, and often obfuscate alternative paths to the same or
other destinations. Designing search engines is a hard challenge; many
searches are ‘precision’ searches aimed at the recall of an individual
token, but many others, such as holiday planning or weighing scientific
literature, involve ‘exploratory’ activities and credibility judgments
of sources. Thinking about how best to represent results for these
multiple purposes is complex (and indeed, Google is currently soliciting
feedback on how it might improve in this
respect[^24]). Even with technological improvements,
we should raise awareness about the ways in which technology mediates
our access to information, and education should reflect the importance
of this awareness while also training our associated critical evaluation
and credibility judgment skills.

##References {.references}

Adams, Tim. 'Google and the Future of Search: Amit Singhal and the
Knowledge Graph', The Guardian , 19 January 2013,
http://www.theguardian.com/technology/2013/jan/19/google-search-knowledge-graph-singhal-interview.

Clark, Andy, and David Chalmers. ‘The Extended Mind’, *Analysis* 58.1
(1998): 7-19.

Connell, Derrick. ' Bing Social Updates Arrive Today: For Every Search,
There is Someone Who Can Help', Bing Blogs, 17 January 2013,
http://www.bing.com/blogs/site\_blogs/b/search/archive/2013/01/17/bing-social-updates-arrive-today-for-every-search-there-is-someone-who-can-help.aspx.

Fricker, Miranda. *Epistemic Injustice: Power and the Ethics of
Knowing,* Oxford: Oxford University Press, 2009.

Garfield, Eugene. *When Is a Negative Search Result Positive? Essays of
an Information Scientist* vol. 1, 12 August 1970,
http://www.garfield.library.upenn.edu/essays/V1p117y1962-73.pdf.

Knight, Simon. ' Danish Use of Internet in Exams – Epistemology,
Pedagogy, Assessment…' Finding Knowledge blog, 23 July 2013,
http://people.kmi.open.ac.uk/knight/2013/07/danish-use-of-internet-in-exams-epistemology-pedagogy-assessment/.

\_\_\_\_\_. ' Is Google Making Me [Stupid|smarter]… How About Bing?'
Finding Knowledge blog, 23 January 2013,
http://people.kmi.open.ac.uk/knight/2013/01/is-google-making-me-stupid-or-smarter-how-about-bing/.

\_\_\_\_\_. 'The Pragmatic Web: More than Just Semantics
Contextualized', Finding Knowledge blog, 4 January 2014,
http://people.kmi.open.ac.uk/knight/2013/01/the-pragmatic-web-more-than-just-semantics-contextualised/.

Knight, Simon and Neil Mercer, ‘The Role of Exploratory Talk in
Classroom Search Engine Tasks’, in *Technology, Pedagogy and Education*,
forthcoming, 2014.

Nadamoto, Akiyo, Eiji Aramaki, Takeshi Abekawa, and Yohei Murakami.
‘Content Hole Search in Community-type Content Using Wikipedia’, In
*Proceedings of the 11th International Conference on Information
Integration and Web-based Applications & Services*, 25-32, 2009,
http://dl.acm.org/citation.cfm?id=1806353.

Resnick, Paul, R. Kelly Garrett, Travis Kriplean, Sean A. Munson, and
Natalie Jomini Stroud. ‘Bursting Your (Filter) Bubble: Strategies for
Promoting Diverse Exposure’, in *Proceedings of the 2013 Conference on
Computer Supported Cooperative Work Companion*, 95–100, 2013,
http://dl.acm.org/citation.cfm?id=2441981.

Russell, Dan. 'Why Knowing Search Isn't the Same as Having an
Education', SearchReSearch blog, 1 August 2011,
http://searchresearch1.blogspot.co.uk/2011/08/why-knowing-search-isnt-same-as-having.html.

Simperl, Elena, Devika P. Madalli, Denny Vrandevcić, and Enrique
Alfonseca. ‘DiversiWeb 2011’, in *ACM SIGIR Forum*, 45 (2011): 49-53,
http://dl.acm.org/citation.cfm?id=1988861.

Simpson, Thomas W. ‘Evaluating Google as an Epistemic Tool’,
*Metaphilosophy* 43.4 (2012): 426-445.

Singh, Rahul, Ya-Wen Hsu, and Naureen Moon. ‘Multiple Perspective
Interactive Search: a Paradigm for Exploratory Search and Information
Retrieval on the Web’, *Multimedia Tools and Applications* 62.2 (2013):
507-543.

Patrick Thomas, 'Give Us Your Feedback on Search Policies', Inside
Search blog, 23 August 2013,
http://insidesearch.blogspot.co.uk/2013/08/give-us-your-feedback-on-search-policies.html.

Verbeke, Mathias, Bettina Berendt, and Siegfried Nijssen. ‘Data Mining,
Interactive Semantic Structuring, and Collaboration: A Diversity-Aware
Method for Sense-Making in Search’, in *Proceedings of First
International Workshop on Living Web, Collocated with the 8th
International Semantic Web Conference (ISWC-2009). CEUR Workshop
Proceedings, Washington, DC, USA*. Vol. 515, 2009,
http://www.liacs.nl/home/snijssen/publications/iswc2009.pdf.

White, Ryen W. ‘Beliefs and Biases in Web Search’, *SIGIR’13,* Dublin,
Ireland, 28 July-1 August, 2013,
http://research.microsoft.com/en-us/um/people/ryenw/papers/WhiteSIGIR2013.pdf.

##Notes {.notes}

[^1]: Andy Clark and David Chalmers, ‘The Extended Mind’, *Analysis* 58.1
    (1998): 7-19,
    http://www.philosophy.ed.ac.uk/people/clark/pubs/TheExtendedMind.pdf.

[^2]: Simon Knight, 'Danish Use of Internet in Exams – Epistemology,
    Pedagogy, Assessment…' Finding Knowledge blog, 23 July 2013,
    http://people.kmi.open.ac.uk/knight/2013/07/danish-use-of-internet-in-exams-epistemology-pedagogy-assessment/.

[^3]: See for discussion and critique of these articles Simon Knight, ‘ Is
    Google Making Me [Stupid|smarter]… How About Bing?' Finding Knowledge
    blog, 23 January 2013,
    http://people.kmi.open.ac.uk/knight/2013/01/is-google-making-me-stupid-or-smarter-how-about-bing/.

[^4]: Amongst others, Dan Russell discusses these issues: 'Why Knowing
    Search Isn't the Same as Having an Education', SearchReSearch blog,
    1 August 2011,
    http://searchresearch1.blogspot.co.uk/2011/08/why-knowing-search-isnt-same-as-having.html.

[^5]: Tim Adams, 'G oogle and the Future of Search: Amit Singhal and the
    Knowledge Graph', The Guardian , 19 January 2013,
    http://www.theguardian.com/technology/2013/jan/19/google-search-knowledge-graph-singhal-interview.

[^6]: Derrick Connell, ' Bing Social Updates Arrive Today: For Every
    Search, There is Someone Who Can Help', Bing Blogs, 17 January 2013,
    http://www.bing.com/blogs/site\_blogs/b/search/archive/2013/01/17/bing-social-updates-arrive-today-for-every-search-there-is-someone-who-can-help.aspx.

[^7]: See, http://actualfacebookgraphsearches. tumblr.com/.

[^8]: See for example Miranda Fricker, Epistemic Injustice: Power and the
    Ethics of Knowing , Oxford: Oxford University Press, 2009.

[^9]: Thomas W. Simpson, ‘Evaluating Google as an Epistemic Tool’,
    *Metaphilosophy* 43.4 (2012): 426-445,
    http://people.ds.cam.ac.uk/tws21/preprints/2012\_Metaphilosophy\_Evaluating%20Google%20as%20an%20Epistemic%20Tool\_preprint.pdf.

[^10]: Simpson, ‘Evaluating Google as an Epistemic Tool’, p. 439.

[^11]: See for example this post and references on it in Simon Knight, 'The
    Pragmatic Web: More than Just Semantics Contextualized', Finding
    Knowledge blog, 4 January 2014,
    http://people.kmi.open.ac.uk/knight/2013/01/the-pragmatic-web-more-than-just-semantics-contextualised/.

[^12]: I am grateful to Rebecca Ferguson at the Open University for these
    examples.

[^13]: Interestingly Garfield discussed this in Eugene Garfield, *When Is a
    Negative Search Result Positive? Essays of an Information Scientist*
    vol. 1, 12 August 1970, pp. 117-118,
    http://www.garfield.library.upenn.edu/essays/V1p117y1962-73.pdf.
    According to Google Scholar (September 2013) that paper has been
    cited six times since then, most prominently by Marchionini
    discussing exploratory search – readers might be entertained to
    consider whether this is a positive negative result…Certainly it
    suggests an interesting lack of exploration of this area.

[^14]: Simon Knight and Neil Mercer, ‘The Role of Exploratory Talk in
    Classroom Search Engine Tasks’, in *Technology, Pedagogy and
    Education*, forthcoming, 2014.

[^15]: Ryen W. White, ‘Beliefs and Biases in Web Search’, *SIGIR’13,*
    Dublin, Ireland, 28 July-1 August, 2013,
    http://research.microsoft.com/e

[^16]: See also Martin Feuz's article in this volume.

[^17]: See for example, Elena Simperl et al., ‘DiversiWeb 2011’, In *ACM
    SIGIR Forum*, 45 (2011): 49-53,
    http://dl.acm.org/citation.cfm?id=1988861.

[^18]: Paul Resnick et al., ‘Bursting Your (Filter) Bubble: Strategies for
    Promoting Diverse Exposure’, in *Proceedings of the 2013 Conference
    on Computer Supported Cooperative Work Companion*, 95-100, 2013,
    http://dl.acm.org/citation.cfm?id=2441981.

[^19]: See, http://project.liquidpub.org/tools.

[^20]: Mathias Verbeke, Bettina Berendt, and Siegfried Nijssen, ‘Data
    Mining, Interactive Semantic Structuring, and Collaboration: A
    Diversity-Aware Method for Sense-Making in Search’, In *Proceedings
    of First International Workshop on Living Web, Collocated with the
    8th International Semantic Web Conference (ISWC-2009). CEUR Workshop
    Proceedings, Washington, DC, USA*. Vol. 515, 2009,
    http://www.liacs.nl/home/snijssen/publications/iswc2009.pdf.

[^21]: Rahul Singh, Ya-Wen Hsu, and Naureen Moon, ‘Multiple Perspective
    Interactive Search: a Paradigm for Exploratory Search and
    Information Retrieval on the Web’, *Multimedia Tools and
    Applications* 62.2 (2013): 507-543.

[^22]: Akiyo Nadamoto et al., ‘Content Hole Search in Community-type
    Content Using Wikipedia’, in *Proceedings of the 11th International
    Conference on Information Integration and Web-based Applications &
    Services*, 25-32, 2009, http://dl.acm.org/citation.cfm?id=1806353.

[^23]: Nadamoto et al., ‘Content Hole Search’.

[^24]: Patrick Thomas, 'Give Us Your Feedback on Search Policies', Inside
    Search blog, 23 August 2013,
    http://insidesearch.blogspot.co.uk/2013/08/give-us-your-feedback-on-search-policies.html.



